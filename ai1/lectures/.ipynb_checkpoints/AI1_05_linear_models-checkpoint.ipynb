{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Linear Models</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Equations</h1>\n",
    "<ul>\n",
    "    <li>From school, the equation of a straight line:\n",
    "        $$y = a + bx$$\n",
    "        E.g. $y = 3 + 2x$\n",
    "    </li>\n",
    "    <li>From the point of view of plotting this line, what's $a$? What's $b$?</li>\n",
    "    <li>In general,\n",
    "        $$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$$\n",
    "        <ul>\n",
    "            <li>$\\beta_0,\\ldots,\\beta_n$ are numbers, called the <b>coefficients</b>;</li>\n",
    "            <li>$x_1,\\ldots,x_n$ are the variables;</li>\n",
    "            <li>each of the things being added together is called a <b>term</b>.</li>\n",
    "        </ul>\n",
    "        So a linear equation is the sum of a number of terms, where each term is either a constant or the\n",
    "        product of a constant and a variable.\n",
    "    </li>\n",
    "    <li>Given a linear equation and the values of the variables ($x_1,\\ldots,x_n$), we can <b>evaluate</b>\n",
    "        the equation, i.e. work out the value of $y$.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Class exercises</h1>\n",
    "<ul>\n",
    "    <li>Which of these are linear equations?\n",
    "        <ol>\n",
    "            <li>$y = 6 + 2x_1 + 4x_3 + x_7$</li>\n",
    "            <li>$y = 6x_1 - 3x_2$</li>\n",
    "            <li>$y = 3 + \\sin(x_1)$</li>\n",
    "            <li>$y = 3x_0^0 + 7x_1^1 + 19x_3^2$</li>\n",
    "            <li>$y = 3 + 14x_1x_2 + 12x_3$</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Evaluate $y = 2 + 3x_1 + 4x_2 + 5x_3$:\n",
    "        <ol>\n",
    "            <li>in the case that $x_1 = 1, x_2 = 1, x_3 = 1$</li>\n",
    "            <li>in the case that $x_1 = 0, x_2 = 1, x_3 = 5$</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Equations and Vectors</h1>\n",
    "<ul>\n",
    "    <li>Give a linear equation $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$, \n",
    "        <ul>\n",
    "            <li>we can gather the variables into a row vector $\\rv{x_1,x_2, \\ldots, x_n}$</li>\n",
    "            <li>we can gather the coefficients (except $\\beta_0$) into a column vector\n",
    "                $\\cv{\\beta_1\\\\ \\beta_2\\\\ \\vdots\\\\ \\beta_n}$ (of the same dimension, $n$)\n",
    "            </li>\n",
    "            <li>E.g. from $y = 12 + 3x_1 + 4x_2 + 5x_3$, we get $\\v{x} = \\rv{x_1, x_2, x_3}$ and\n",
    "                $\\v{\\beta} = \\cv{3\\\\4\\\\5}$\n",
    "            </li>\n",
    "            <li>What are the two vectors for $y = 7 + 20x_1 + x_3$?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Hence, the linear equation $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$ can\n",
    "        equivalently be written in this form:\n",
    "        $$y = \\beta_0 + \\sum_{i=1}^n \\v{x}_i\\v{\\beta}_i$$\n",
    "    </li>\n",
    "    <li>It can also, equivalently, be written in this form:\n",
    "        $$y = \\beta_0 + \\v{x}\\v{\\beta}$$\n",
    "    </li>\n",
    "    <li>Hence, to evaluate a linear equation, simply multiply the two vectors and add $\\beta_0$.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Evaluating a linear equation in numpy</h2>\n",
    "<ul>\n",
    "    <li>If you had to evaluate a linear equation, you might be tempted to write a loop:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate y = 12 + 3x1 + 4x2 + 5x3 in the case where x1=7, x2=3, x3=20\n",
    "y = 12\n",
    "for (beta_i, x_i) in zip(np.array([3, 4, 5]), np.array([7, 3, 20])):\n",
    "    y += beta_i * x_i\n",
    "    \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>\n",
    "        But you don't need to write your own loop: use numpy library's matrix multiplication method:\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 12 + np.array([3, 4, 5]).dot(np.array([7, 3, 20]))\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Linear Equations and Vectors: Tidying the maths</h2>\n",
    "<ul>\n",
    "    <li>Give a linear equation $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$, \n",
    "        <ul>\n",
    "            <li>we can gather the variables into a row vector but include an extra variable \n",
    "                $x_0$, whose value will always be 1: $\\rv{1,x_1,x_2, \\ldots, x_n}$</li>\n",
    "            <li>we can gather <em>all</em> the coefficients (including $\\beta_0$) into a column vector\n",
    "                $\\cv{\\beta_0\\\\ \\beta_1\\\\ \\beta_2\\\\ \\vdots\\\\ \\beta_n}$ (of the same dimension, $n+1$)\n",
    "            </li>\n",
    "            <li>E.g. from $y = 12 + 3x_1 + 4x_2 + 5x_3$, we get $\\v{x} = \\rv{1, x_1, x_2, x_3}$ and\n",
    "                $\\v{\\beta} = \\cv{12\\\\3\\\\4\\\\5}$\n",
    "            </li>\n",
    "            <li>What are the two vectors for $y = 7 + 20x_1 + x_3$?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Hence, the linear equation $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$ can\n",
    "        equivalently be written in this form:\n",
    "        $$y = \\sum_{i=0}^n \\v{x}_i\\v{\\beta}_i$$\n",
    "    </li>\n",
    "    <li>It can also, equivalently, be written in this form:\n",
    "        $$y = \\v{x}\\v{\\beta}$$\n",
    "    </li>\n",
    "    <li>Hence, to evaluate a linear equation, simply multiply the two vectors.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([12, 3, 4, 5]).dot(np.array([1, 7, 3, 20]))\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Evaluating Linear Equations and Matrices</h1>\n",
    "<ul>\n",
    "    <li>Suppose you need to evaluate the same linear equation lots of times &mdash; with different values \n",
    "        for $\\v{x}$\n",
    "        <ul>\n",
    "            <li>E.g. evaluate $y = 12 + 3x_1 + 4x_2 + 5x_3$ for\n",
    "                <ul>\n",
    "                    <li>$x_1 = 7, x_2 = 3, x_3 = 20$ and</li>\n",
    "                    <li>$x_1 = 10, x_2 = 20, x_3 = 0$ and</li>\n",
    "                    <li>$x_1 = 1, x_2 = 1, x_3 = 1$ and</li>\n",
    "                    <li>$x_1 = 100, x_2 = 0, x_3 = -2$</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>If we gather the values for the variables into a matrix, $\\v{X}$, but with an extra element \n",
    "        $\\v{x}_0^{(i)}$ in each row $i$, all of which will be 1, then we can obtain all the\n",
    "        results by simple matrix multiplication:\n",
    "        $$y = \\v{X}\\v{\\beta}$$\n",
    "        <ul>\n",
    "            <li>E.g.\n",
    "                $$\n",
    "                \\v{y} =\n",
    "                \\begin{bmatrix}\n",
    "                    1 & 7 & 3 & 20 \\\\\n",
    "                    1 & 10 & 20 & 0 \\\\\n",
    "                    1 & 1 & 1 & 1 \\\\\n",
    "                    1 & 100 & 0 & -2\n",
    "                \\end{bmatrix}\n",
    "                \\cv{12\\\\ 3\\\\ 4\\\\ 5}\n",
    "                $$\n",
    "            </li>\n",
    "        </ul>\n",
    "        It produces a vector of results, e.g. $\\v{y} = \\cv{145\\\\122\\\\24\\\\302}$\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Evaluating a linear equation multiple times in numpy</h2>\n",
    "<ul>\n",
    "    <li>Same story: no loop, use matrix mutliplication:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([145, 122,  24, 302])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[1, 7, 3, 20], [1, 10, 20, 0], [1, 1, 1, 1], [1, 100, 0, -2]]).dot(np.array([12, 3, 4, 5]))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>This is <b>vectorization</b> again: concise, fast code!</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Models</h1>\n",
    "<ul>\n",
    "    <li>Recall: We want to learn a model from a labeled training set.</li>\n",
    "    <li>For now, let's content ourselves with learning a linear model.</li>\n",
    "    <li>We want  to find a linear equation that best fits the training examples.</li>\n",
    "    <li>We'll start by assuming there's only one feature.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Regression: with one feature</h1>\n",
    "<ul>\n",
    "    <li>We'll read in the Cork Property Prices dataset and ignore all features other than\n",
    "        $\\mathit{flarea}$.\n",
    "    </li>\n",
    "    <li>For the purposes of this explanation, we won't scale the data. <!-- : so no need for a <code>ColumnTransformer</code>.--></li>\n",
    "    <li>We'll also extract the prices (the target values).</li>\n",
    "    <li>Also for the purposes of this explanation, we will use the entire dataset as our training set.\n",
    "        <ul>\n",
    "            <li>We will learn later that using <em>all</em> the data for training is usually not\n",
    "                the right thing to do.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_training_set():\n",
    "    plt.figure()\n",
    "    plt.title(\"Training set\")\n",
    "    plt.scatter(df[\"flarea\"], df[\"price\"], color = 'green')\n",
    "    plt.xlabel(\"Floor area (sq metres)\")\n",
    "    plt.xlim(0, 500)\n",
    "    plt.ylabel(\"Price (000 euros)\")\n",
    "    plt.ylim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "show_training_set()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>The goal of our learning algorithm is to fit a linear model to this data:\n",
    "        $$\\hat{y} = \\beta_0 + \\beta_1 \\times \\mathit{flarea}$$\n",
    "    </li>\n",
    "    <li>In other words, our goal is to choose values for $\\beta_0$ and $\\beta_1$.\n",
    "        <ul>\n",
    "            <li>From the point of view of plotting this line, what's $\\beta_0$? What's $\\beta_1$?</li>\n",
    "            <li>E.g. we could choose $\\beta_0 = 800$ and $\\beta_1 = -5$.</li>\n",
    "            <li>Or we could choose $\\beta_0 = 200$ and $\\beta_1 = 5$.</li>\n",
    "        </ul>\n",
    "        Let's refer to any particular choice as $h_{\\v{\\beta}}$ ($h$ for <b>hypothesis</b>).\n",
    "            <ul>\n",
    "                <li>The first example above is $h_{\\rv{800, -5}}$</li>\n",
    "                <li>The second example above is $h_{\\rv{200, 5}}$</li>\n",
    "            </ul>\n",
    "    </li>\n",
    "    <li>But there is an infinite set of linear models the algorithm can choose from:\n",
    "        <ul>\n",
    "            <li>an infinite number of straight lines it can draw;</li>\n",
    "            <li>or, equivalently, an infinite set of values from which it can pick $\\beta_0$ and $\\beta_1$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>We want it to choose the one that best fits the data.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Loss functions</h1>\n",
    "<ul>\n",
    "    <li>The algorithm needs a function that measures how well a model (hypothesis) fits the data.\n",
    "        <ul>\n",
    "            <li>This is called its <b>loss function</b>, designated $J$.</li>\n",
    "            <li>The function takes in a particular $h_{\\v{\\beta}}$ and gives it a score.\n",
    "                <ul>\n",
    "                    <li>Low numbers are better!</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>For each $\\v{x}$ in the training set, it will compare $h_{\\v{\\beta}}(\\v{x})$, which is the\n",
    "                <em>prediction</em> that $h_{\\v{\\beta}}$ makes on $\\v{x}$, with the <em>actual</em>\n",
    "                value $y$.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The loss function most usually used for linear regression is the <b>mean squared error</b>, i.e.:\n",
    "        <ul>\n",
    "            <li>the difference between the prediction and the actual value, squared;</li>\n",
    "            <li>but averaged over all the examples in the training set.</li>\n",
    "        </ul>\n",
    "        $$J(\\v{X}, \\v{y}, \\v{\\beta}) = \\frac{1}{m}\\sum_{i=1}^m(h_{\\v{\\beta}}(\\v{x}^{(i)}) - \\v{y}^{(i)})^2$$\n",
    "        <ul>\n",
    "            <li>Why do you think we square the differences? (Two reasons.)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The best model is the one that <em>minimizes</em> the loss function.</li>\n",
    "    <li>This is often referred to as <b>ordinary least-squares regression</b> (OLS):\n",
    "        <ul>\n",
    "            <li>\"least\" because we are minimizing the loss;</li>\n",
    "            <li>\"squares\" because the loss is mean squared error; and</li>\n",
    "            <li>\"ordinary\" to distinguish it from many variants that came later.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>In fact, we often divide by 2:\n",
    "        $$J(\\v{X}, \\v{y}, \\v{\\beta}) = \\frac{1}{2m}\\sum_{i=1}^m(h_{\\v{\\beta}}(\\v{x}^{i)}) - \\v{y}^{(i)})^2$$\n",
    "        &mdash; the 'winner' is still the same, but this makes the calculus 'tidier' later\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>The loss function in numpy</h2>\n",
    "<ul>\n",
    "    <li>Looks like a loop: work out $h_{\\v{\\beta}}$ for each $\\v{x}^{(i)}$.\n",
    "        <ul>\n",
    "            <li>But $h_{\\v{\\beta}}$ is a linear equation, and we want to evaluate it lots of times (for\n",
    "                each example $\\v{x}^{(i)}$).\n",
    "            </li>\n",
    "            <li>So we use the vectorized approach from above (assuming all the examples contain an\n",
    "                extra element, $\\v{x}_0^{(i)} = 1$).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>So our code can simply do this:\n",
    "        $$J(\\v{X}, \\v{y}, \\v{\\beta}) = \\frac{1}{2}mean((\\v{X}\\v{\\beta} - \\v{y})^2)$$\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for OLS regression (assumes X contains all 1s in its first column)\n",
    "def J(X, y, beta):\n",
    "    return np.mean((X.dot(beta) - y) ** 2) / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Now let's find a model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature-values (just flarea) and the target values \n",
    "X = df[[\"flarea\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Add the extra column to X\n",
    "X_augmented = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Keep modifying $\\v{\\beta}$ until you find the lowest loss:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1147ac97e7cf4648a9b0cc535ea3ec04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, description='beta0', max=1000), FloatSlider(value=0.0, description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_linear_model(beta0, beta1):\n",
    "    show_training_set()\n",
    "    beta = np.array([beta0, beta1])\n",
    "    xvals = np.array([[1, 0], [1, 500]])\n",
    "    plt.plot(xvals, xvals.dot(beta), color = \"blue\")\n",
    "    plt.show()\n",
    "    print(\"Loss: \" + str(J(X_augmented, y, beta)))\n",
    "    \n",
    "interactive_plot = interactive(show_linear_model, beta0=(0,1000), beta1=(-10,10,.1))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Regression: with multiple features</h1>\n",
    "<ul>\n",
    "    <li>We considered only one feature ($\\mathit{flarea}$).\n",
    "        <ul>\n",
    "            <li>This enabled easy visualisation on a 2D plot.</li>\n",
    "            <li>The model is a straight line.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The only differences when we move to more than one feature:\n",
    "        <ul>\n",
    "            <li>We can't plot so easily.</li>\n",
    "            <li>The model is a plane when there are two features.</li>\n",
    "            <li>The model is a hyperplane when there are more than two features.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><em>All the maths and the Python for the loss function remain the same</em>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Now let's find a model using two features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")\n",
    "\n",
    "# Get the feature-values (just bdrms and bthrms) and the target values \n",
    "X = df[[\"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Add the extra column to X\n",
    "X_augmented = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_3D_training_set():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_title(\"Training set and learned model\")\n",
    "    ax.scatter(X[:,0], X[:,1], y, color = \"green\")\n",
    "    ax.set_xlabel(\"Bedrooms\")\n",
    "    ax.set_xlim(0,10)\n",
    "    ax.set_ylabel(\"Bathrooms\")\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.set_zlabel(\"Price (000 euros)\")\n",
    "    ax.set_zlim(0, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Keep modifying $\\v{\\beta}$ until you find the lowest loss:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9833ce5acc4c1f993707a58060d387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, description='beta0', max=1000), IntSlider(value=0, description='bet…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_linear_model(beta0, beta1, beta2):\n",
    "    show_3D_training_set()\n",
    "    beta = np.array([beta0, beta1, beta2])\n",
    "    xvals = np.linspace(0, 10, 2)\n",
    "    yvals = np.linspace(0, 10, 2)\n",
    "    xxvals, yyvals = np.meshgrid(xvals, yvals)\n",
    "    plt.gca().plot_surface(xxvals, yyvals, beta[0] + beta[1] * xxvals + beta[2] * yyvals, color=(0, 0, 1, 0.2))\n",
    "    plt.show()\n",
    "    print(\"Loss: \" + str(J(X_augmented, y, beta)))\n",
    "    \n",
    "interactive_plot = interactive(show_linear_model, beta0=(0,1000), beta1=(-100,100), beta2=(-100,100))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>We can't do a similar example with 3 or more features&hellip;\n",
    "        <ul>\n",
    "            <li>&hellip;because we can't plot them.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Finding OLS Models</h1>\n",
    "<ul>\n",
    "    <li>We've been trying out different values for $\\v{\\beta}$, looking for the model with\n",
    "        lowest mean squared error&hellip;\n",
    "        <ul>\n",
    "            <li>&hellip;by trial and error!</li>\n",
    "        </ul>\n",
    "        In practice, it is not done by trial-and-error.\n",
    "    </li>\n",
    "    <li>There are two main methods:\n",
    "        <ul>\n",
    "            <li>the <b>normal equation</b> (<code>LinearRegression</code> class in scikit-learn);</li>\n",
    "            <li>various forms of <b>gradient descent</b> (<code>SGDRegressor</code> class in scikit-learn).</li>\n",
    "        </ul>\n",
    "        We'll look at the details in the next two lectures.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
