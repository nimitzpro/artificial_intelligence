{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Gradient Descent</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Acknowledgement</h1>\n",
    "<ul>\n",
    "    <li>I based 5 of the diagrams on ones to be found in A. G&eacute;ron: <i>Hands-On Machine Learning with Scikit-Learn, Keras &amp;\n",
    "        TensorFlow (2nd edn)</i>, O'Reilly, 2019\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li><b>Gradient Descent</b> is a generic method for finding optimal solutions to problems that involve\n",
    "        minimizing a loss function.\n",
    "    </li>\n",
    "    <li>It is a <em>search</em> in the model's <b>parameter space</b> for values of the parameters that minimize \n",
    "        the loss function.\n",
    "    </li>\n",
    "    <li>Conceptually:\n",
    "        <ul>\n",
    "            <li>\n",
    "                 It starts with an initial guess for the values of the parameters.\n",
    "            </li>\n",
    "            <li>\n",
    "                Then repeatedly:\n",
    "                <ul>\n",
    "                    <li>It updates the parameter values  &mdash; hopefully to reduce the loss.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <img src=\"images/fog.jpg\" alt=\"\" />\n",
    "    </li>\n",
    "    <li>\n",
    "        Ideally, it keeps doing this until <b>convergence</b> &mdash; changes to the parameter values do not result\n",
    "        in lower loss.\n",
    "    </li>\n",
    "    <li>The key to this algorithm is how to update the parameter values.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>The update rule</h2>\n",
    "<ul>\n",
    "     <li>To update the parameter values to reduce the loss:\n",
    "         <ul>\n",
    "             <li>Compute the gradient vector.\n",
    "                 <ul>\n",
    "                     <li>But this points 'uphill' and we want to go 'downhill'.</li>\n",
    "                     <li>And we want to make 'baby steps' (see later), so we use a <b>learning rate</b>, \n",
    "                         $\\alpha$, which is between 0 and 1.\n",
    "                     </li>\n",
    "                 </ul>\n",
    "             </li>\n",
    "             <li>So subtract $\\alpha$ times the gradient vector from $\\v{\\beta}$.</li>\n",
    "         </ul>\n",
    "         $$\\v{\\beta} \\gets \\v{\\beta} - \\alpha\\nabla_{\\v{\\beta}}J(\\v{X}, \\v{y}, \\v{\\beta})$$\n",
    "         Or\n",
    "         $$\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$$\n",
    "     </li>\n",
    "     <li>(BTW, this is vectorized. Naive loop implementations are wrong: they lose the\n",
    "         <em>simultaneous</em> update of the $\\v{\\beta}_j$.)\n",
    "     </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Gradient descent algorithm</h2>\n",
    "<ul>\n",
    "    <li>Pseudocode (in fact, this is for <b>batch gradient descent</b>, see later):\n",
    "        <ul style=\"background: lightgrey; list-style: none\">\n",
    "            <li>initialize $\\v{\\beta}$ randomly\n",
    "            <li>\n",
    "                repeat until convergence\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        $\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$\n",
    "                    </li>\n",
    "                </ul>\n",
    "             </li>\n",
    "        </ul>\n",
    "    </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Baby steps</h2>\n",
    "<ul>\n",
    "    <li>We'll use  an example with a single feature/single parameter $\\beta_1$ in order to visualize.</li>\n",
    "    <li>We update $\\beta_1$ gradually, one baby step at a time, unitl the algorithm converges on minimum loss:\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps1.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>The size of the steps is determined by <!--a <b>hyperparameter</b> called--> the learning rate.\n",
    "    <!--\n",
    "        <ul>\n",
    "            <li>(Hyperparamters are explained in CS4619)</li>\n",
    "        </ul>\n",
    "       -->\n",
    "    </li>\n",
    "    <li>If the learning rate is too small, it will take many updates until convergence:\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps2.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>If the learning rate is too big, the algorithm might jump across the valley &mdash; it may even end up with\n",
    "        higher loss than before, making the next step bigger.\n",
    "        <ul>\n",
    "            <li>This might make the algorithm <b>diverge</b>.\n",
    "            </li>\n",
    "        </ul>\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps3.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Why we need to scale for Gradient Descent</h2>\n",
    "<ul>\n",
    "    <li>If we are doing OLS regression using the Normal Equation, we do not need to scale the features.\n",
    "        But if we are doing OLS regression using Gradient Descent, we do need to scale the features.\n",
    "    </li>\n",
    "    <li>If features have different ranges, it affects the shape of the 'bowl'.</li>\n",
    "    <li>E.g. features 1 and 2 have similar ranges of values &mdash; a 'bowl':\n",
    "        <figure>\n",
    "            <img src=\"images/scaled.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>The algorithm goes straight towards the minimum.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>E.g. feature 1 has smaller values than feature 2 &mdash; an elongated 'bowl':\n",
    "        <figure>\n",
    "            <img src=\"images/unscaled.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>Since feature 1 has smaller values, it takes a larger change in $\\v{\\beta}_1$ to affect \n",
    "                the loss function, which is why it is elongated.\n",
    "            </li>\n",
    "            <li>It takes more steps to get to the minimum &mdash; steeply down but not really towards the\n",
    "                goal, followed by a long march down a nearly flat valley.\n",
    "            </li>\n",
    "            <li>It makes it more difficult to choose a value for the learning rate that avoids diveregence:\n",
    "                a value that suits one feature may not suit another.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Variants of Gradient Descent</h2>\n",
    "<ul>\n",
    "    <li>There are, in fact, three variants:\n",
    "        <ul>\n",
    "            <li>Batch Gradient Descent;</li>\n",
    "            <li>Stochastic Gradient Descent; and</li>\n",
    "            <li>Mini-batch Gradient Descent.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Batch Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>The pseudocode we saw earlier (repeated here for convenience) is Batch Gradient Descent:\n",
    "        <ul style=\"background: lightgrey; list-style: none\">\n",
    "            <li>initialize $\\v{\\beta}$ randomly\n",
    "            <li>\n",
    "                repeat until convergence\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        $\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$\n",
    "                    </li>\n",
    "                </ul>\n",
    "             </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Why is it called <em>Batch</em> Gradient Descent?\n",
    "        <ul>\n",
    "            <li>The update involves a calculation over the <em>entire</em> training set $\\v{X}$\n",
    "                on every iteration.\n",
    "            </li>\n",
    "            <li>This can be slow for large training sets.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Batch Gradient Descent in numpy</h2>\n",
    "<ul>\n",
    "    <li>For the hell of it, let's implement it ourselves.</li>\n",
    "    <li>Again for the purposes of this explanation, we will use the entire dataset as our training set.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for OLS regression (assumes X contains all 1s in its first column)\n",
    "def J(X, y, beta):\n",
    "    return np.mean((X.dot(beta) - y) ** 2) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent_for_ols_linear_regression(X, y, alpha, num_iterations):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_iterations)\n",
    "    \n",
    "    for iter in range(num_iterations):\n",
    "        beta -= (1.0 * alpha / m) * X.T.dot(X.dot(beta) - y)\n",
    "        Jvals[iter] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Add the extra column to X\n",
    "X = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([352.29732897, 175.20819504,   0.35503878,   1.46074231])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Batch Gradient Descent\n",
    "beta, Jvals = batch_gradient_descent_for_ols_linear_regression(X, y, alpha = 0.03, num_iterations = 500)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Bear in mind that the coefficients it finds are on the scaled data.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>It's a good idea to plot the values of the loss function against the number of iterations.\n",
    "    </li>\n",
    "    <li>For OLS regression done using Batch Gradient Descent, if the loss ever increases, then:\n",
    "        <ul>\n",
    "            <li>\n",
    "                the code might be incorrect; or\n",
    "            </li>\n",
    "            <li>\n",
    "                the value of $\\alpha$ is too big and is causing divergence.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAGFCAYAAACVJHu/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj9ElEQVR4nO3de5TdZX3v8feXEGREZUBTCgMWWmkoGCUyYrr0nCoqiVbLSK3F4oG2LDmtV85p05KzXKVVrNgsL6Wn9pRbBS8FqjFwPGqaAraeLrlMDBJBUwJYYQCJhoCVORDC9/yxnyE7w1x+M/s2e+/3a61Zs/fzuz37l5WZz/yeW2QmkiRJVezT6QpIkqTuYXCQJEmVGRwkSVJlBgdJklSZwUGSJFVmcJAkSZUZHCRJUmUGB0mSVJnBQeoTEfHpiDi/geNvj4hXN69GT5/3+xHxumaft+K1W/KZpF62b6crIGl+IuIQ4EHg0Mx8sNXXy8zjWn2NduvFzyS1mk8cpO71EmB7q0NDRHTdHxjdWGepWxgcpO71EuC26TZGxPKI+FZE/CQirgL2r9uWEfGiuvd7NWOU5oM/jojbgJ9GxL71TQrl9R9GxG0R8UhEXBUR9ed/WURsLtf+h7K9UjNJRBwWEV+MiO0RcU9EvK9u27kRcVc57x0R8ZYKdZ6pnm35TFIvMThI3WsZ0wSHiNgPWA98BjgY+Afg1+d4/rcDvwoMZuaTU2x/G7AKOIpaiPntumt/Cfh0ufbfA2+Z4vip6r0P8L+BbwNDwGuBcyJiZdnlLuA/AQcCfwZ8NiIOnaXOU9ZzGk3/TFKvMThI3WumJw4rgMXAJzNzV2Z+Abhljue/MDPvzczxGbbfn5k7qP2yP77u2vuW7bsycx1wc8VrvhxYkpkfzMwnMvNu4GLgNIDM/Idyzacy8yrgTuDEWeo8XT3b9ZmknmI7oNSFImIRcCy1v8ynchgwlplZV/bvc7zMvbNsr+9b8Vi55nTXnu1cE34OOCwidtaVLQK+ARARZwD/HTiybHsO8IJZrjNdPafSis8k9RSfOEjd6Rep/UK9Y5rtDwBDERF1ZS+se/0Y8Oy69z87xTlyirIqprr2ERWPvRe4JzMH676em5lvjIifo/b04T3A8zNzEPgOUH+d+dZ5No18JqmnGByk7vQS4N8y8/Fptn8TeBJ4X0QsjohT2fuR/q3Ab0XEoohYBfxKE+v2TWA38J7SQfGUSdeeyc3AT0onx4FSvxdHxMuBA6gFg+0AEfE7wIubWO+ZNPKZpJ5icJC60zKmb6YgM58ATqXWuW8H8JvAurpd3g+8GdgJnE6tI2VT1F37rHL+dwBfBqYLOfXH7gbeRK1vwT3Aj4BLgAMz8w7gY9R+if+Q2j3412bVe5Z6zfszSb0m9m6yk9QNIuIG4POZeXGn61JFRNwE/K/M/LtO16VZevEzSVX4xEHqMhHxemp/bX+p03WZTkT8SkT8bHmsfya1ppWvdbpejejFzyTNR1uDQ5lgZUtE3BoRo6Xs4IjYGBF3lu8HlfKIiAsjYluZkOVldec5s+x/Z/kPPFF+Qjn/tnJsPLMWUveKiC3AWuCtmfmjTtdnBkupNaXsBP6AWn0f6GiNGteLn0mas7Y2VUTE94Hh+h94EfEXwI7MvCAizgUOysw/jog3Au8F3gi8AvjLzHxFRBwMjALD1DpKbQJOyMyHI+Jm4H3ATcBXqI25/mrbPqAkST1uITRVnAJcXl5fDozUlV+RNTcCg2WGuJXAxszckZkPAxuBVWXb8zLzxjLW+oq6c0mSpCZod3BI4B8jYlNEnF3KDql73PcgcEh5PcTeE6zcV8pmKr9vinJJktQk7Z458lWZORYRPwNsjIjv1W/MzIyIlredlNByNsABBxxwwjHHHNPqS0qStCBs2rTpR5m5ZL7HtzU4ZOZY+f5QRHyJ2gQqP4yIQzPzgdLc8FDZfYy9Z2Y7vJSNAa+eVP71Un74FPtPVY+LgIsAhoeHc3R0tLEPJklSl4iIuU4/v5e2NVVExAER8dyJ18DJ1KaLvRaYGBlxJnBNeX0tcEYZXbECeKQ0aWwATo6Ig8oIjJOBDWXboxGxooymOKPuXJIkqQna+cThEOBLZYTkvtQmr/laRNwCXB0RZ1FbhOdtZf+vUBtRsY3avPq/A5CZOyLiQ+xZ6e+DZSU7gHdRW/Z2APhq+ZIkSU3S9zNH2lQhSeonEbEpM4fne/xCGI4pSZK6hMFBkiRVZnCQJEmVGRwkSVJlBgdJklSZwUGSJFVmcJAkSZW1e62KBW/95jHWbtjK/TvHOWxwgNUrlzKy3LWyJEkCg8Ne1m8eY826LYzv2g3A2M5x1qzbAmB4kCQJmyr2snbD1qdDw4TxXbtZu2Frh2okSdLCYnCoc//O8TmVS5LUbwwOdQ4bHJhTuSRJ/cbgUGf1yqUMLF60V9nA4kWsXrm0QzWSJGlhsXNknYkOkI6qkCRpagaHSUaWDxkUJEmahk0VkiSpMoODJEmqzOAgSZIqMzhIkqTKDA6SJKkyg4MkSarM4CBJkiozOEiSpMoMDpIkqTKDgyRJqszgIEmSKnOtiims3zzmQleSJE3B4DDJ+s1jrFm3hfFduwEY2znOmnVbAAwPkqS+Z1PFJGs3bH06NEwY37WbtRu2dqhGkiQtHAaHSe7fOT6nckmS+onBYZLDBgfmVC5JUj8xOEyyeuVSBhYv2qtsYPEiVq9c2qEaSZK0cNg5cpKJDpCOqpAk6ZkMDlMYWT5kUJAkaQo2VUiSpMoMDpIkqTKDgyRJqszgIEmSKjM4SJKkygwOkiSpMoODJEmqzOAgSZIqMzhIkqTKDA6SJKkyp5yexvrNY65XIUnSJAaHKazfPMaadVsY37UbgLGd46xZtwXA8CBJ6ms2VUxh7YatT4eGCeO7drN2w9YO1UiSpIXB4DCF+3eOz6lckqR+YXCYwmGDA3MqlySpXxgcprB65VIGFi/aq2xg8SJWr1zaoRpJkrQw2DlyChMdIB1VIUnS3gwO0xhZPmRQkCRpEpsqJElSZQYHSZJUmcFBkiRVZnCQJEmVGRwkSVJlBgdJklSZwUGSJFVmcJAkSZUZHCRJUmVtDw4RsSgiNkfEl8v7oyLipojYFhFXRcR+pfxZ5f22sv3IunOsKeVbI2JlXfmqUrYtIs5ttK7rN4/xyguu56hz/w+vvOB61m8ea/SUkiR1tU48cXg/8N269x8FPpGZLwIeBs4q5WcBD5fyT5T9iIhjgdOA44BVwKdKGFkE/DXwBuBY4O1l33lZv3mMNeu2MLZznATGdo6zZt0Ww4Mkqa+1NThExOHArwKXlPcBnAR8oexyOTBSXp9S3lO2v7bsfwpwZWY+npn3ANuAE8vXtsy8OzOfAK4s+87L2g1bGd+1e6+y8V27Wbth63xPKUlS12v3E4dPAn8EPFXePx/YmZlPlvf3ARMrSw0B9wKU7Y+U/Z8un3TMdOXzcv/O8TmVS5LUD9oWHCLiTcBDmbmpXdecoS5nR8RoRIxu3759yn0OGxyYU7kkSf2gnU8cXgn8WkR8n1ozwknAXwKDETGxvPfhwEQngjHgCICy/UDgx/Xlk46ZrvwZMvOizBzOzOElS5ZMWdnVK5cysHjRXmUDixexeuXSKp9VkqSe1LbgkJlrMvPwzDySWufG6zPzdOAG4K1ltzOBa8rra8t7yvbrMzNL+Wll1MVRwNHAzcAtwNFllMZ+5RrXzre+I8uH+MipyxgaHCCAocEBPnLqMkaWz7v1Q5Kkrrfv7Lu03B8DV0bE+cBm4NJSfinwmYjYBuygFgTIzNsj4mrgDuBJ4N2ZuRsgIt4DbAAWAZdl5u2NVGxk+ZBBQZKkOlH7I75/DQ8P5+joaKerIUlSW0TEpswcnu/xzhwpSZIqMzhIkqTKDA6SJKkyg4MkSarM4CBJkiozOEiSpMoMDpIkqbKFMAHUgrV+8xhrN2zl/p3jHDY4wOqVS50QSpLU1wwO01i/eYw167Y8vbT22M5x1qzbAmB4kCT1LZsqprF2w9anQ8OE8V27Wbtha4dqJElS5xkcpnH/zvE5lUuS1A8MDtM4bHBgTuWSJPUDg8M0Vq9cysDiRXuVDSxexOqVSztUI0mSOs/OkdOY6ADpqApJkvYwOMxgZPmQQUGSpDo2VUiSpMoMDpIkqTKDgyRJqszgIEmSKjM4SJKkygwOkiSpMoODJEmqzHkcZuHS2pIk7WFwmIFLa0uStDebKmbg0tqSJO3N4DADl9aWJGlvBocZuLS2JEl7MzjMwKW1JUnam50jZ+DS2pIk7c3gMAuX1pYkaQ+bKiRJUmUGB0mSVJnBQZIkVWZwkCRJlRkcJElSZY6qqMCFriRJqjE4zMKFriRJ2sOmilm40JUkSXsYHGbhQleSJO1hcJiFC11JkrSHwWEWLnQlSdIedo6chQtdSZK0h8GhAhe6kiSpxqYKSZJUmcFBkiRVZnCQJEmVGRwkSVJlBgdJklSZoyoqcqErSZIMDpW40JUkSTU2VVTgQleSJNUYHCpwoStJkmoMDhW40JUkSTUGhwpc6EqSpBo7R1bgQleSJNUYHCpyoStJkmyqkCRJc2BwkCRJlRkcJElSZQYHSZJUmZ0j58D1KiRJ/a5tTxwiYv+IuDkivh0Rt0fEn5XyoyLipojYFhFXRcR+pfxZ5f22sv3IunOtKeVbI2JlXfmqUrYtIs5tZv0n1qsY2zlOsme9ivWbx5p5GUmSFrR2NlU8DpyUmS8FjgdWRcQK4KPAJzLzRcDDwFll/7OAh0v5J8p+RMSxwGnAccAq4FMRsSgiFgF/DbwBOBZ4e9m3KVyvQpKkNgaHrPmP8nZx+UrgJOALpfxyYKS8PqW8p2x/bUREKb8yMx/PzHuAbcCJ5WtbZt6dmU8AV5Z9m8L1KiRJanPnyPJk4FbgIWAjcBewMzOfLLvcB0x0GhgC7gUo2x8Bnl9fPumY6cqbwvUqJElqc3DIzN2ZeTxwOLUnBMe08/oTIuLsiBiNiNHt27dXOsb1KiRJ6tBwzMzcCdwA/DIwGBETozsOByZ6G44BRwCU7QcCP64vn3TMdOVTXf+izBzOzOElS5ZUqvPI8iE+cuoyhgYHCGBocICPnLrMURWSpL7StuGYEbEE2JWZOyNiAHg9tQ6PNwBvpdYn4UzgmnLIteX9N8v26zMzI+Ja4PMR8XHgMOBo4GYggKMj4ihqgeE04Lea+Rlcr0KS1O/aOY/DocDlZfTDPsDVmfnliLgDuDIizgc2A5eW/S8FPhMR24Ad1IIAmXl7RFwN3AE8Cbw7M3cDRMR7gA3AIuCyzLy9fR9PkqTeF5nZ6Tp01PDwcI6Ojna6GpIktUVEbMrM4fke75TTkiSpMqecniOnnZYk9TODwxxMTDs9MYPkxLTTgOFBktQXbKqYA6edliT1O4PDHDjttCSp3xkc5sBppyVJ/c7gMAdOOy1J6nd2jpyDiQ6QjqqQJPUrg8McOe20JKmf2VQhSZIqMzhIkqTKbKqYB2ePlCT1K4PDHDl7pCSpn9lUMUfOHilJ6mcGhzly9khJUj8zOMyRs0dKkvqZwWGOnD1SktTPZu0cGREfB24rX7dn5uMtr9UC5uyRkqR+VmVUxTZgBfBO4Jci4kH2BIlbgH/ptzDh7JGSpH41a3DIzE/Vv4+Io4BlwEuA3wf+NiJ+PzM3tKaKkiRpoZjzPA6ZeQ9wD3AtQEQcCnwZMDhIktTjGp4AKjMfiIjPN6My3cTZIyVJ/agpM0dm5seacZ5u4eyRkqR+5XDMeXD2SElSvzI4zIOzR0qS+pXBYR6cPVKS1K8MDvPg7JGSpH7lstrz4OyRkqR+ZXCYJ2ePlCT1I5sqJElSZT5xaICTQEmS+o3BYZ6cBEqS1I9sqpgnJ4GSJPUjg8M8OQmUJKkfGRzmyUmgJEn9yOAwT04CJUnqR3aOnCcngZIk9SODQwOcBEqS1G8MDg1wHgdJUr8xOMyT8zhIkvqRnSPnyXkcJEn9yOAwT87jIEnqRwaHeXIeB0lSPzI4zJPzOEiS+pGdI+fJeRwkSf3I4NAA53GQJPUbg0ODnMtBktRPDA4NcC4HSVK/sXNkA5zLQZLUbwwODXAuB0lSvzE4NMC5HCRJ/cbg0ADncpAk9Rs7RzbAuRwkSf3G4NCgyeFhomOk4UGS1IsMDg1ySKYkqZ/Yx6FBDsmUJPUTg0ODHJIpSeonBocGOSRTktRPDA4NckimJKmf2DmyQQ7JlCT1E4NDEzgkU5LULwwOTeCQTElSv2hbH4eIOCIiboiIOyLi9oh4fyk/OCI2RsSd5ftBpTwi4sKI2BYRt0XEy+rOdWbZ/86IOLOu/ISI2FKOuTAioh2fzSGZkqR+0c7OkU8Cf5CZxwIrgHdHxLHAucB1mXk0cF15D/AG4OjydTbwN1ALGsB5wCuAE4HzJsJG2eeddcetasPnckimJKlvtC04ZOYDmfmt8vonwHeBIeAU4PKy2+XASHl9CnBF1twIDEbEocBKYGNm7sjMh4GNwKqy7XmZeWNmJnBF3blayiGZkqR+0ZHhmBFxJLAcuAk4JDMfKJseBA4pr4eAe+sOu6+UzVR+3xTlU13/7IgYjYjR7du3N/ZhcEimJKl/tD04RMRzgC8C52Tmo/XbypOCbHUdMvOizBzOzOElS5Y0fL6R5UN85NRlDA0OEMDQ4AAfOXWZHSMlST2nrcEhIhZTCw2fy8x1pfiHpZmB8v2hUj4GHFF3+OGlbKbyw6cob4uR5UOsXrmUwwYHnh6SuX5z2y4vSVJbtHNURQCXAt/NzI/XbboWmBgZcSZwTV35GWV0xQrgkdKksQE4OSIOKp0iTwY2lG2PRsSKcq0z6s7VchNDMsd2jpPsGZJpeJAk9ZJ2PnF4JfBfgJMi4tby9UbgAuD1EXEn8LryHuArwN3ANuBi4F0AmbkD+BBwS/n6YCmj7HNJOeYu4Kvt+GDgkExJUn9o2wRQmfl/genmVXjtFPsn8O5pznUZcNkU5aPAixuo5rw5JFOS1A9c5KpJHJIpSeoHBocmcUimJKkfGByaZGJI5uDA4qfL9l/s7ZUk9RZ/szXZ408+9fTrhx/b5cgKSVJPMTg0kSMrJEm9zuDQRI6skCT1OoNDEzmyQpLU6wwOTTTVyIoAXnNM4+thSJK0EBgcmmhk+RC/fsLQXrNcJfDFTWN2kJQk9QSDQ5Pd8L3tz1je0w6SkqReYXBoMjtISpJ6mcGhyewgKUnqZQaHJnPqaUlSLzM4NJlTT0uSepm/0VrEqaclSb3I4NACTj0tSepVBocWcGSFJKlXGRxawJEVkqReZXBoAaeeliT1KoNDCzj1tCSpVxkcWsSppyVJvcjg0CJ2kJQk9SKDQ4tM1xHywLqJoSRJ6jYGhxZZvXIpi/eJZ5T/9Ikn7ecgSepaBocWGVk+xHP23/cZ5bt2p/0cJEldy+DQQjsf2zVluf0cJEndyuDQQk4EJUnqNQaHFpqqn8PifcIltiVJXcvg0GqT+0c+s7+kJEldw+DQQms3bGXX7r2ngbJzpCSpmxkcWshJoCRJvcbg0EJOAiVJ6jUGhxZyEihJUq8xOLSQk0BJknqNwaHFnARKktRLDA4tZj8HSVIvMTi0mP0cJEm9xODQYvZzkCT1EoNDG9jPQZLUKwwObWA/B0lSrzA4tIH9HCRJvcLg0Ab2c5Ak9QqDQ5tM189hzH4OkqQuYnBok+n6OQTYXCFJ6hoGhzZZvXIpz+zlAAk2V0iSuobBoU1Glg+R02yzuUKS1C0MDm00ZHOFJKnLGRzayOYKSVK3Mzi00UzNFc4iKUnqBgaHNpuuucJZJCVJ3cDg0GbOIilJ6mYGhzabaRbJP7329g7USJKk6gwOHTDdLJI7x3f51EGStKAZHDpgulkkwdEVkqSFzeDQAatXLp12m5NBSZIWMoNDB4wsH+KgZ089isLJoCRJC5nBoUPOe/NxTgYlSeo6BocOcTIoSVI3Mjh00OA0kz45GZQkaaEyOHRQTNVWATzx5O72VkSSpIoMDh003XwOj+16yg6SkqQFqW3BISIui4iHIuI7dWUHR8TGiLizfD+olEdEXBgR2yLitoh4Wd0xZ5b974yIM+vKT4iILeWYCyOm+3t+4ZhpPgdnkZQkLUTtfOLwaWDVpLJzgesy82jguvIe4A3A0eXrbOBvoBY0gPOAVwAnAudNhI2yzzvrjpt8rQVnpvkcnEVSkrQQtS04ZOa/ADsmFZ8CXF5eXw6M1JVfkTU3AoMRcSiwEtiYmTsy82FgI7CqbHteZt6YmQlcUXeuBWum+RzAYZmSpIWn030cDsnMB8rrB4FDyush4N66/e4rZTOV3zdF+ZQi4uyIGI2I0e3btzf2CRp03puPm3abs0hKkhaaTgeHp5UnBdNNbdDsa12UmcOZObxkyZJ2XHJaziIpSeomnQ4OPyzNDJTvD5XyMeCIuv0OL2UzlR8+RXlXmGkWSTtJSpIWkk4Hh2uBiZERZwLX1JWfUUZXrAAeKU0aG4CTI+Kg0inyZGBD2fZoRKwooynOqDvXgjfTLJJ2kpQkLSTtHI7598A3gaURcV9EnAVcALw+Iu4EXlfeA3wFuBvYBlwMvAsgM3cAHwJuKV8fLGWUfS4px9wFfLUdn6tZhhyaKUnqAlHrWtC/hoeHc3R0tNPVYP3mMc656tZpt79jxQs5f2RZ+yokSepJEbEpM4fne3ynmypUzDY083M3/sAmC0lSxxkcFpCZhmbaUVKStBAYHBaQ2Z462FFSktRpBocFZrqhmRN86iBJ6iSDwwIzsnyI01e8cNrtO8d38YH1W9pYI0mS9jA4LEDnjyyzo6QkaUEyOCxQs3WUdAEsSVInGBwWqNk6SroAliSpEwwOC9hMTx0A+zpIktrO4LCAjSyfdmVwwL4OkqT2MzgscDOtYeGkUJKkdjM4LHCrVy6dcV4Hh2dKktrJ4LDAzTavA8Bnb/yB4UGS1BYGhy5w/sgy3mF4kCQtAAaHLjHbpFBgeJAktZ7BoYvMto4FGB4kSa1lcOgiVfo7gOFBktQ6BocuU6W/AxgeJEmtYXDoQoYHSVKnGBy61FzCw3F/8jVnmJQkNYXBoYudP7KMA/ZbNOt+P31iN+dcdasBQpLUMINDl/vwW5axz2xDLYqJAGHzhSRpvgwOXW5k+RAff9vxDCyu/k/52Rt/wOkXf7OFtZIk9arIzE7XoaOGh4dzdHS009Voig+s38Jnb/zBnI456NmLOe/Nx826EqckqTdExKbMHJ7v8T5x6CFVO0zWe/ixXfZ/kCRV5hOHHnriMGH95jHWrLuN8V1Pzet4n0JIUu9q9ImDwaEHg8OERgPEAfst4sNvWWaAkKQeYnBoUC8HhwmnX/xN/vWuHQ2fxycRktT9DA4N6ofgAM0LD/V8IiFJ3cfg0KB+CQ5Qa7r402tvZ+f4rpZexycTkrRwGRwa1E/BoV6j/R/my1AhSZ1lcGhQvwaHCZ0KEFUYMiSp+QwODer34DChXc0Y7WTwkKRnMjg0yODwTL0YItrN0CJpoTI4NMjgMDuDhKQJjqbqfgaHBhkc5s4gIUnd64HLz+HxB+6suK7yM+3bzMqoP4wsH5ryr40PrN/C5278Af0dRSWptxkc1DTnjyzj/JFlU27zKYUk9QaDg9piuqcUkxkwJGlhMzhoQakaMGZik4kktU7fd46MiO3Av3e6Hj3sBcCPOl2Jdtln4HkHL3ruC46IffZpayjf/dgjLHr2ge28ZN/xHreH97n1dv34Pp56YnzenSP7PjiotSJitJFhP6rG+9x63uP28D63XqP3eJ9mVkaSJPU2g4MkSarM4KBWu6jTFegT3ufW8x63h/e59Rq6x/ZxkCRJlfnEQZIkVWZwUEMi4rKIeCgivlNXdnBEbIyIO8v3g0p5RMSFEbEtIm6LiJd1rubdIyKOiIgbIuKOiLg9It5fyr3PTRIR+0fEzRHx7XKP/6yUHxURN5V7eVVE7FfKn1Xebyvbj+zoB+gyEbEoIjZHxJfLe+9zE0XE9yNiS0TcGhGjpaxpPy8MDmrUp4FVk8rOBa7LzKOB68p7gDcAR5evs4G/aVMdu92TwB9k5rHACuDdEXEs3udmehw4KTNfChwPrIqIFcBHgU9k5ouAh4Gzyv5nAQ+X8k+U/VTd+4Hv1r33PjffazLz+Lphl037eWFwUEMy81+AHZOKTwEuL68vB0bqyq/ImhuBwYg4tC0V7WKZ+UBmfqu8/gm1H7hDeJ+bptyr/yhvF5evBE4CvlDKJ9/jiXv/BeC1ETHvCXX6SUQcDvwqcEl5H3if26FpPy8MDmqFQzLzgfL6QeCQ8noIuLduv/tKmSoqj2qXAzfhfW6q8vj8VuAhYCNwF7AzM58su9Tfx6fvcdn+CPD8tla4e30S+CPgqfL++Xifmy2Bf4yITRFxdilr2s8L16pQS2VmRoRDd5ogIp4DfBE4JzMfrf/Dy/vcuMzcDRwfEYPAl4BjOluj3hMRbwIeysxNEfHqDlenl70qM8ci4meAjRHxvfqNjf688ImDWuGHE4+6yveHSvkYcETdfoeXMs0iIhZTCw2fy8x1pdj73AKZuRO4Afhlao9tJ/7Aqr+PT9/jsv1A4MftrWlXeiXwaxHxfeBKak0Uf4n3uakyc6x8f4haCD6RJv68MDioFa4FziyvzwSuqSs/o/TiXQE8UvfoTNMobbqXAt/NzI/XbfI+N0lELClPGoiIAeD11PqS3AC8tew2+R5P3Pu3Atenk+LMKjPXZObhmXkkcBq1+3Y63uemiYgDIuK5E6+Bk4Hv0MSfF04ApYZExN8Dr6a2CuYPgfOA9cDVwAuprTz6tszcUX4B/k9qozAeA34nM0c7UO2uEhGvAr4BbGFPu/D/oNbPwfvcBBHxEmodxhZR+4Pq6sz8YET8PLW/jA8GNgPvyMzHI2J/4DPU+pvsAE7LzLs7U/vuVJoq/jAz3+R9bp5yL79U3u4LfD4zPxwRz6dJPy8MDpIkqTKbKiRJUmUGB0mSVJnBQZIkVWZwkCRJlRkcJElSZQYHqYtEREbEx+re/2FE/GmTzv3piHjr7Hs2fJ3fiIjvRsQNk8oPi4gvlNfHR8Qbm3jNwYh411TXkjQ3BgepuzwOnBoRL+h0RerVzfpXxVnAOzPzNfWFmXl/Zk4El+OBOQWHWeowCDwdHCZdS9IcGByk7vIkcBHw3yZvmPzEICL+o3x/dUT8c0RcExF3R8QFEXF6RNwcEVsi4hfqTvO6iBiNiH8r6wpMLP60NiJuiYjbIuK/1p33GxFxLXDHFPV5ezn/dyLio6XsT4BXAZdGxNpJ+x9Z9t0P+CDwmxFxa0T8ZpkN77JS580RcUo55rcj4tqIuB64LiKeExHXRcS3yrVPKae/APiFcr61E9cq59g/Iv6u7L85Il5Td+51EfG1iLgzIv6i7n58utR1S0Q8499C6mUuciV1n78Gbpv4RVbRS4Ffojb73t3AJZl5YkS8H3gvcE7Z70hq89r/AnBDRLwIOIPaNLQvj4hnAf8aEf9Y9n8Z8OLMvKf+YhFxGPBR4ATgYWor9Y2U2RhPojZj4JSz02XmEyVgDGfme8r5/pzadMO/W6aGvjki/qmuDi8ps+DtC7ylLAL2AuDGEmzOLfU8vpzvyLpLvrt22VwWEceUuv5i2XY8tVkLHwe2RsRfAT8DDGXmi8u5Bme471LP8YmD1GUy81HgCuB9czjslsx8IDMfp7Zc9MQv/i3UwsKEqzPzqcy8k1rAOIbaXPdnRG3J6ZuoLWt8dNn/5smhoXg58PXM3F6WQ/4c8J/nUN/JTgbOLXX4OrA/talzATZm5o7yOoA/j4jbgH+itjzwIczsVcBnATLze9Sm450IDtdl5iOZ+f+oPVX5OWr35ecj4q8iYhXwaAOfS+o6PnGQutMngW8Bf1dX9iTlj4GI2AfYr27b43Wvn6p7/xR7/xyYPAd9Uvtl/N7M3FC/oaw18NP5VH4eAvj1zNw6qQ6vmFSH04ElwAmZuStqqzDu38B16+/bbmDfzHw4Il4KrAR+D3gb8LsNXEPqKj5xkLpQ+Qv7amodDSd8n1rTAMCvAYvncerfiIh9Sr+Hnwe2AhuA34/a0t5ExC9GbdW9mdwM/EpEvCAiFgFvB/55DvX4CfDcuvcbgPeWBXmIiOXTHHcg8FAJDa+h9oRgqvPV+wa1wEFponghtc89pdIEsk9mfhH4ALWmEqlvGByk7vUxaquSTriY2i/rbwO/zPyeBvyA2i/9rwK/Vx7RX0LtMf23SofCv2WWp5VlWd5zqS2X/G1gU2ZeM9Mxk9wAHDvRORL4ELUgdFtE3F7eT+VzwHBEbKHWN+N7pT4/ptY34zuTO2UCnwL2KcdcBfx2adKZzhDw9dJs8llgzRw+l9T1XB1TkiRV5hMHSZJUmcFBkiRVZnCQJEmVGRwkSVJlBgdJklSZwUGSJFVmcJAkSZUZHCRJUmX/H8Y+MAr0fq22AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>The algorithm gives us the problem of choosing the number of iterations.</li>\n",
    "    <li>An alternative is to use a very large number of iterations but exit when the gradient vector\n",
    "        becomes tiny:\n",
    "        <ul>\n",
    "            <li>when its norm becomes smaller than <b>tolerance</b>, $\\eta$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Here's an interactive version that allows you to choose the value of $\\alpha$ and to decide\n",
    "        whether to scale the data or not.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b088416a6c14250a5ead62a7e83dff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='scale'), Dropdown(description='alpha', options=(('0.00â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bgd(scale=True, alpha=0.03):\n",
    "    # Get the feature-values and the target values \n",
    "    X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "    y = df[\"price\"].values\n",
    "    # Scale the data, if requested\n",
    "    if scale:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    # Add the extra column to X\n",
    "    X = add_dummy_feature(X)\n",
    "    # Run the Batch Gradient Descent\n",
    "    beta, Jvals = batch_gradient_descent_for_ols_linear_regression(X, y, alpha, num_iterations = 3000)\n",
    "    # Display beta\n",
    "    print(\"beta: \", beta)\n",
    "    # Plot loss\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.title(\"$J$ during learning\")\n",
    "    plt.xlabel(\"Number of iterations\")\n",
    "    plt.xlim(1, Jvals.size)\n",
    "    plt.ylabel(\"$J$\")\n",
    "    plt.ylim(3500, 50000)\n",
    "    xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "    plt.scatter(xvals, Jvals)\n",
    "    plt.show()\n",
    "    \n",
    "interactive_plot = interactive(bgd, {'manual': True}, \n",
    "    scale=True, alpha=[(\"0.00009\", 0.00009), (\"0.0009\", 0.0009), (\"0.009\", 0.009), (\"0.09\", 0.09), (\"0.9\", 0.9)]) \n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>\n",
    "        Some people suggest a variant of Batch Gradient Descent in which the value of $\\alpha$ is decreased\n",
    "        over time, i.e. its value in later iterations is smaller\n",
    "        <ul>\n",
    "            <li>Why do they suggest this? </li>\n",
    "            <li>And why isn't it necessary?\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>(But, we'll revisit this idea in Stochastic Gradient Descent.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Stochastic Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>As we saw, in each iteration, Batch Gradient Descent does a calculation on the entire\n",
    "        training set, which, for large training sets, may be slow.\n",
    "    </li>\n",
    "    <li><b>Stochastic Gradient Descent (SGD)</b>:\n",
    "        <ul>\n",
    "            <li>On each iteration, it picks just <em>one</em> training example $\\v{x}$ at random and computes \n",
    "                the gradients on just that\n",
    "                one example\n",
    "                $$\\v{\\beta} \\gets \\v{\\beta} - \\alpha\\v{x}^T(\\v{x}\\v{\\beta} - \\v{y})$$\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>This gives huge speed-up.</li>\n",
    "    <li>It enables us to train on huge training sets since only one example needs to be in memory in each iteration.\n",
    "    </li>\n",
    "    <li>But, because it is stochastic (the randomness), the loss will not necessarily decrease on each iteration:\n",
    "        <ul>\n",
    "            <li><em>On average</em>, the loss decreases, but in any one iteration, loss may go up or down.</li>\n",
    "            <li>Eventually, it will get close to the minimum, but it will continue to go up and down a bit.\n",
    "                <ul>\n",
    "                    <li>So, once you stop it, the $\\v{\\beta}$ will be close to the best, but not \n",
    "                        necessarily optimal.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>SGD in scikit-learn</h2>\n",
    "<ul>\n",
    "    <li>The <code>fit</code> method of scikit-learn's <code>SGDRegressor</code> class is doing\n",
    "        what we have described:\n",
    "        <ul>\n",
    "            <li>You must scale the features but it inserts the extra column of 1s for us.</li>\n",
    "            <li>You can supply a <code>learning_rate</code> and lots of other things\n",
    "                (in the code below, we'll just use the defaults).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>(Again, we'll train on the whole dataset.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Create the SGDRegressor and fit the model\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>SGD in numpy</h2>\n",
    "<ul>\n",
    "    <li>For the hell of it, let's implement a simple version ourselves</li>\n",
    "    <li>(Again, we'll train on the whole dataset.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_for_ols_linear_regression(X, y, alpha, num_epochs):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_epochs * m)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(m):\n",
    "            rand_idx = np.random.randint(m)\n",
    "            xi = X[rand_idx:rand_idx + 1]\n",
    "            yi = y[rand_idx:rand_idx + 1]\n",
    "            beta -= alpha * xi.T.dot(xi.dot(beta) - yi)\n",
    "            Jvals[epoch * m + i] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>(One common alternative to the code above is to shuffle between epochs and remove the randomness within the\n",
    "        inner loop.)\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Add the extra column to X\n",
    "X = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([344.02655246, 187.82981714, -12.5300742 ,  -7.30668866])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Stochastic Gradient Descent\n",
    "beta, Jvals = stochastic_gradient_descent_for_ols_linear_regression(X, y, alpha = 0.03, num_epochs = 50)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAGFCAYAAABtxIBIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZQc1Xnn8d8zo5EYYawXLECMAIEgIsbCyMggR7sbg+OIDSGMMRhYvCa7HLNxnMQYR2tprV1wFsdytMY+zsZOIE7ARmAJEGPZgAnhZbOHRZIHRmIsjCLxJhhhCVsvyDBIo5ln/+jbQ3VNV7/MdHd1T38/5/SZnttd1beru6ueunXvc83dBQAA0JJ2BQAAQH0gKAAAAJIICgAAQEBQAAAAJBEUAACAgKAAAABIIigAAAABQQEAAJBEUAA0DTO7zcxuGsPyW8zswxWsUna9L5nZ71R6vSW+dlXeE9CoJqRdAQCjY2bHSNolaaa7/6Lar+fuZ1T7NWptPL4nYCxoKQAa1/slvV7tgMDMGu7koRHrDNQDggKgcZ0p6ZmkB81svpk9bWYHzGy1pCMij7mZnRr5P+fSQmjS/6KZPSPpTTObEG3mD/f/3MyeMbP9ZrbazKLr/4CZ9YTXvjs8XtKlCzM73szuNbPXzexFM/uzyGNLzez5sN5nzexjJdS5UD1r8p6ARkFQADSueUoICsxsoqQuSd+XNF3S3ZI+Xub6r5R0oaSp7n44z+OfkHSBpJOVCVD+MPLa90m6Lbz2XZI+lmf5fPVukfQjSZsldUj6iKTrzGxxeMrzkv6tpCmSvizpDjObWaTOeeuZoOLvCWgkBAVA4yrUUrBQUpukb7r7gLvfI+mnZa7/W+7+irv3F3h8p7vvUeZAflbktSeExwfcfa2kjSW+5gclzXD3v3D3Q+7+gqRbJV0hSe5+d3jNIXdfLWmbpHOK1DmpnrV6T0DD4Lob0IDMrFXSbypzRp3P8ZL6PHdu9JfLfJlXijwe7cvwVnjNpNcutq6skyQdb2b7ImWtkv6vJJnZpyRdL2l2eOxdkt5T5HWS6plPNd4T0DBoKQAa028oE9Q/m/D4a5I6zMwiZSdG7r8laXLk/+PyrMPzlJUi32ufUOKyr0h60d2nRm5HufvvmdlJyrQa/Imko919qqSfSYq+zmjrXMxY3hPQMAgKgMZ0pqR/dfeDCY8/KemwpD8LHe4uUW4z+yZJ/8HMWs3sAkm/XcG6PSlpUNKfhNe+OPbahWyU9EboMNge6vc+M/ugpCOVOei/Lklm9p8kva+C9S5kLO8JaBgEBUBjmqfkSwdy90OSLlGmo9xeSZdLWht5yuckXSRpn6SrlOmUWBGR174mrP+Tkn4sKSmAiS47GOp1lqQXJf1S0t9LmuLuz0r6ujIH6F3KbIMnKlXvIvUa9XsCGonlXiID0AjM7DFJd7r7rWnXpRRmtkHS37r7P6Zdl0oZj+8JoKUAaDBm9lFlzpLvS7suSczst83suNDUfrUylzt+kna9xmI8vicgrqZBQUgO0mtmm8ysO5RNN7OHzWxb+Dst8vxlZrbdzLZGxinLzM4O69luZt/Kdv4xs0khoch2M9tgZrNr+f6AajOzXkkrJV3q7r9Muz4FzFXm8sZ+SV9Qpr6vpVulMRuP7wnIUdPLB2b2kqQF0Z2Zmf2VpD3uvsLMlkqa5u5fNLP3KpMg5BxlhgP9s6TfcPdBM9uozDXR9ZIeUGbs8INm9seSznT3PzKzKyR9zN0vr9kbBACggdXD5YOLJd0e7t8uqTNS/gN3P+juL0raLumckL3s3e7+ZBgz/L3YMtl13SPpI7EhRAAAIEGtgwKX9E9m9pSZXRvKjs02wYW/x4TyDuUmB3k1lHWE+/HynGVCitP9ko6uwvsAAGDcqXVGw0XuvtMyU74+bGbPFXhuvjN8L1BeaJncFWcCkmsl6cgjjzz79NNPL1xrAADGiaeeeuqX7j4j32M1DQrcfWf4u9vM7lOmv8AuM5vp7q+FSwO7w9NfVW7GsFmSdobyWXnKo8u8apmpU6dI2pOnHrdIukWSFixY4N3d3RV6hwAA1DczS0x5XrPLB2Z2pJkdlb0v6XeVSVG6TtLV4WlXS/phuL9O0hVhRMHJkk6TtDFcYjhgZgtDf4FPxZbJrutSSY86iRgAAChJLVsKjpV0X+j3N0GZxCs/MbOfSlpjZtdI2iHpMkly9y1mtkaZ3O6HJX02ZDuTpM8oM4Vpu6QHw02Svivp+2a2XZkWgitq8cYAABgPmj6jIZcPAADNxMyecvcF+R6rhyGJAACgDhAUAAAASQQFAAAgICgAAACSCAoAAEBAUAAAACQRFAAAgICgAAAASCIoAAAAQdMHBb19+7VoxaPq6ulLuyoAAKSq6YMCSerb169la3sJDAAATY2gIOgfGNTKh7amXQ0AAFJDUBCxc19/2lUAACA1BAURx09tT7sKAACkhqAgaG9r1ZLFc9OuBgAAqZmQdgXqQcfUdi1ZPFed8zvSrgoAAKlp+qBgXscUPbH0/LSrAQBA6rh8AAAAJBEUAACAgKAAAABIIigAAAABQQEAAJBEUAAAAAKCAgAAIImgAAAABAQFAABAEkEBAAAICAoAAIAkggIAABAQFAAAAEkEBQAAICAoAAAAkggKAABAQFAAAAAkERQAAICAoAAAAEgiKAAAAAFBAQAAkERQAAAAgqYPCnr79mvRikfV1dOXdlUAAEhV0wcFktS3r19L7tlMYAAAaGoEBcHAoOvLP9qSdjUAAEgNQUHE3rcG0q4CAACpISgAAACSCApyTG1vS7sKAACkhqAgaGsx3fgHZ6RdDQAAUjMh7QrUg46p7VqyeK4653ekXRUAAFLT9EHBvI4pemLp+WlXAwCA1HH5AAAASCIoAAAAAUEBAACQRFAAAAACggIAACCJoAAAAARNHxQwdTIAABlNHxRImamTl63tJTAAADQ1goKgf2BQKx/amnY1AABIDUFBxM59/WlXAQCA1BAURBw/tT3tKgAAkBqCgqC9rVVLFs9NuxoAAKSm6SdEkpglEQAAKYWWAjNrNbMeM/tx+H+6mT1sZtvC32mR5y4zs+1mttXMFkfKzzaz3vDYt8zMQvkkM1sdyjeY2exi9cnOkkhAAABodmlcPvicpJ9H/l8q6RF3P03SI+F/mdl7JV0h6QxJF0j6tpm1hmW+I+laSaeF2wWh/BpJe939VEnfkPS16r4VAADGj5oGBWY2S9KFkv4+UnyxpNvD/dsldUbKf+DuB939RUnbJZ1jZjMlvdvdn3R3l/S92DLZdd0j6SPZVoQkJC8CACCj1i0F35T0XyUNRcqOdffXJCn8PSaUd0h6JfK8V0NZR7gfL89Zxt0PS9ov6ehilSJ5EQAANQwKzOz3Je1296dKXSRPmRcoL7RMvC7Xmlm3mXUPvrVfEsmLAACoZUvBIkl/YGYvSfqBpPPN7A5Ju8IlAYW/u8PzX5V0QmT5WZJ2hvJZecpzljGzCZKmSNoTr4i73+LuC9x9QevkKcPlJC8CADSzmgUF7r7M3We5+2xlOhA+6u6flLRO0tXhaVdL+mG4v07SFWFEwcnKdCjcGC4xHDCzhaG/wKdiy2TXdWl4jREtBUlIXgQAaGb1kKdghaQ1ZnaNpB2SLpMkd99iZmskPSvpsKTPuvtgWOYzkm6T1C7pwXCTpO9K+r6ZbVemheCKUitB8iIAQLOzMk6kx6VJM0/zBZ/7O5IXAQCagpk95e4L8j1WDy0FqcomLwIAoNkx9wEAAJBEUAAAAAKCAgAAIImgAAAABAQFAABAEkEBAAAICAoAAIAkggIAABAQFAAAAEkEBQAAICAoAAAAkggKAABAQFAAAAAkERQAAICAoAAAAEgiKAAAAAFBAQAAkERQAAAAAoICAAAgiaAAAAAEBAUAAEASQQEAAAgICgAAgCSCAgAAEBAUAAAASQQFAAAgICgAAACSCAoAAEBAUAAAACQRFAAAgICgAAAASCIoAAAAAUEBAACQRFAAAAACggIAACCJoAAAAAQEBQAAQBJBAQAACAgKAACAJIICAAAQEBQAAABJBAXq7duvRSseVVdPX9pVAQAgVU0fFEhS375+LVvbS2AAAGhqBAVB/8CgVj60Ne1qAACQGoKCiJ37+tOuAgAAqSEoiDh+anvaVQAAIDUEBUF7W6uWLJ6bdjUAAEjNhLQrUA86prZryeK56pzfkXZVAABITdMHBfM6puiJpeenXQ0AAFLH5QMAACCJoAAAAAQEBQAAQBJBAQAACAgKAACAJIICAAAQEBQAAABJBAUAACAgKAAAAJIICgAAQEBQAAAAJNUwKDCzI8xso5ltNrMtZvblUD7dzB42s23h77TIMsvMbLuZbTWzxZHys82sNzz2LTOzUD7JzFaH8g1mNrtW7w8AgEZXy5aCg5LOd/f3SzpL0gVmtlDSUkmPuPtpkh4J/8vM3ivpCklnSLpA0rfNrDWs6zuSrpV0WrhdEMqvkbTX3U+V9A1JX6vFGwMAYDyoWVDgGb8O/7aFm0u6WNLtofx2SZ3h/sWSfuDuB939RUnbJZ1jZjMlvdvdn3R3l/S92DLZdd0j6SPZVgQAAFBYTfsUmFmrmW2StFvSw+6+QdKx7v6aJIW/x4Snd0h6JbL4q6GsI9yPl+cs4+6HJe2XdHR13g0AAONLTYMCdx9097MkzVLmrP99BZ6e7wzfC5QXWiZ3xWbXmlm3mXW//vrrxaoNAEBTSGX0gbvvk/S4Mn0BdoVLAgp/d4envSrphMhisyTtDOWz8pTnLGNmEyRNkbQnz+vf4u4L3H3BjBkzKvSuAABobLUcfTDDzKaG++2SfkfSc5LWSbo6PO1qST8M99dJuiKMKDhZmQ6FG8MlhgNmtjD0F/hUbJnsui6V9GjodwAAAIqYUMPXminp9jCCoEXSGnf/sZk9KWmNmV0jaYekyyTJ3beY2RpJz0o6LOmz7j4Y1vUZSbdJapf0YLhJ0nclfd/MtivTQnBFTd4ZAADjgDX7ifSCBQu8u7s77WoAAFATZvaUuy/I9xgZDQEAgCSCAgAAEBAUAAAASQQFAAAgICgAAACSCAoAAEBAUAAAACQRFAAAgICgAAAASCIoAAAAAUEBAACQRFAAAAACggIAACCJoAAAAAQEBQAAQBJBAQAACAgKAACApBKCAjO72cz+0Mw+YGaTalGpWurt2685yx7Q8q7etKsCAECqJpTwnO2SFkr6tKTfNLNfSHom3H4q6V/c/WD1qlh9g+66Y/0OSdJNnfNSrg0AAOko2lLg7t929z9y90XuPl3ShZLuDMt+RtLPzWxxletZE3dteCXtKgAAkJpSWgpyuPuLkl6UtE6SzGympB9LeqiyVau9Qfe0qwAAQGrG3NHQ3V9TpuWg4bWapV0FAABSU5HRB+7+9UqsJ21XnntC2lUAACA1DEkEAACSCApyrFq/Q109fWlXAwCAVBAURLiklQ9tTbsaAACkgqAgZue+/rSrAABAKggKYo6f2p52FQAASAVBQcySxXPTrgIAAKkgKIgwSZ3zO9KuBgAAqSAoiPitOdPTrgIAAKkhKIjYsvNA2lUAACA1BAUR+/oHyFMAAGhaBAUx5CkAADQrgoIY8hQAAJoVQUEMeQoAAM2KoCCiva2VPAUAgKY1Ie0KpK2ttUWmTAvBksVzyVMAAGhaTR8UnH7cUepecWHa1QAAIHVcPgAAAJIICgAAQEBQAAAAJBEU6LlfHNDJS+/XohWPks0QANDUmj4oGBgckkvq29evZWt7CQwAAE2r6YOCqP6BQdIcAwCaFkFBDGmOAQDNiqAghjTHAIBmRVAQ0dpipDkGADQtgoKIwSFX98t70q4GAACpICiIuXPDjrSrAABAKggKYoY87RoAAJAOggIAACCJoAAAAAQEBTHTJrelXQUAAFJBUBDR1mq64aIz0q4GAACpmJB2BdLW1toiUyZp0ZLFc9U5vyPtKgEAkIqmDwpOP+4oda+4MO1qAACQOi4fAAAASQQFAAAgICgAAACSCAoAAEBAUAAAACTVMCgwsxPM7DEz+7mZbTGzz4Xy6Wb2sJltC3+nRZZZZmbbzWyrmS2OlJ9tZr3hsW+ZmYXySWa2OpRvMLPZtXp/AAA0ulq2FByW9AV3/01JCyV91szeK2mppEfc/TRJj4T/FR67QtIZki6Q9G0zaw3r+o6kayWdFm4XhPJrJO1191MlfUPS12rxxgAAGA9qFhS4+2vu/nS4f0DSzyV1SLpY0u3habdL6gz3L5b0A3c/6O4vStou6Rwzmynp3e7+pLu7pO/Flsmu6x5JH8m2IiR57hcHdPLS+7VoxaPq6umryHsFAKARpdKnIDTrz5e0QdKx7v6alAkcJB0TntYh6ZXIYq+Gso5wP16es4y7H5a0X9LReV7/WjPrNrPutw/slUvq29evZWt7CQwAAE2r5kGBmb1L0r2SrnP3Nwo9NU+ZFygvtExugfst7r7A3Re0Tp4yXN4/MKiVD20tUCUAAMavmgYFZtamTECwyt3XhuJd4ZKAwt/dofxVSSdEFp8laWcon5WnPGcZM5sgaYqkPeXUcee+/nKeDgDAuFHL0Qcm6buSfu7uN0ceWifp6nD/akk/jJRfEUYUnKxMh8KN4RLDATNbGNb5qdgy2XVdKunR0O+gZMdPbS/znQEAMD7UckKkRZL+o6ReM9sUyv6bpBWS1pjZNZJ2SLpMktx9i5mtkfSsMiMXPuvug2G5z0i6TVK7pAfDTcoEHd83s+3KtBBcUU4F29tatWTx3NG9OwAAGpyVeSI97rxr1lyf8cmbmToZANAUzOwpd1+Q7zGmTmbqZAAAJJHmGAAABAQFAABAEpcPAAB1aHlXr+7a8IoG3dVqpivPPUE3dc5Lu1rjHkEBAKCuLO/q1R3rdwz/P+g+/D+BQXVx+QAAUFfu2vBKWeWoHIICAEBdGUwYKp9UjsohKAAA1JXWhMltk8pROQQFAIC6cuW5J5RVjsqhoyEAoK5kOxMy+qD2aCkAANSdBSdN13FTjpBJOm7KEVpw0vS0q9QUmr6l4LlfHNDJS+9n7gMAqBNdPX1atrZX/QOZOfD69vVr2dpeSWIfXWVN31IwMDgk1ztfuq6evrSrBABNbeVDW4cDgqz+gUGtfGhrSjVqHk0fFETxpQOA9O3c119WOSqHoCCGLx0ApOv4qe1llaNyCApi+NIBQLqWLJ6r9rbWnLL2tlYtWTw3pRo1j6bvaBh33ukz0q4CADS1bGfClQ9t1c59/XQEryGCgpjHnns97SoAQNPrnN9BEJACgoIY+hQAQPq6evpoKUgBQUEMfQoAIF3kKUgPHQ0j6MgCAOkjT0F6mr6loK21RSbRPAUAdaIv4TJuUjkqp+mDgtOPO0rdKy5MuxoAgKDVTIPuectRXVw+AADUlXwBQaFyVA5BAQCgrnQkdPhOKkflEBQAAOoKGQ3TQ1AAAKgrnfM79PGzO4b7ELSa6eNnk8yoFggKAAB1paunT6s3vjLch2DQXas3vsLU9jVAUAAAqCs3rtuigaHcToUDQ64b121JqUbNg6AAAFBX9vUPlFWOymn6oOC5XxzQyUvv16IVj9I0BQBoak0fFAwMDsn1Tm5tAgMAQLNq+qAgitzaAJC+aZPbyipH5RAUxDB1MgCk64aLzlBba25K47ZW0w0XnZFSjZpH0899EBefOpk5vQGgtjrnd6j75T26a0NmWGKrmS7/4Anse2uAloKIeMas7Jzeffv66XcAADVCnoL0EBQE+TJmMac3ANQeeQrSQ1AQDLrr3qf6ciLRpP4F9DsAgOohT0F6CAoi4q0AU9rz93RNKgcAoJERFMREWwHM8j8nqRwAMHaT2/IfmpLKUTmMPoiJjj7Y91ZCE1ZCOVBNjIRBs5jU1qq3BobylqO6CLsi4qMP4sMTi5UD1cJIGDQTTsjS0/RBQVtri0xSx9R2ffWSeTlnXpMnJjRhJZQD1cJIGDQTTsjS0/SXD04/7ih1r7gw72Pbdr9ZVjlQLYyEQTNZsniulty9OWdYYluL5bTkojo45QUaAGdOaDrxDt108K4JggKgAcw+Ov/BP6m8GXT19GnRikeZ+nwcWvnQVg0MxpIXDTqXy2qg6S8f9Pbt1+yl96vVTFeee4Ju6pw3/NikCS06eDhPD9gJ9R9L0VN9fFn/wt6yyse7bMfLbD+LbMdLSXzPxwEul6Wn/o9uNTLorjvW79Dyrt7hsssWzMr73KTyekFP9fEnmwO+1PLxjo6X4xuXy9JDUBCzav2O4fs/3vxa3uckldcLdpi1sbyrV3OWPaDZS+/XnGUP5ASUldaakDErqXy840xyfFuyeK7aYzkJ4kPGG1Ut9xujQVAQEz3vatT82+wwq295V6/uWL8jZxa3eEtTJV157glllY93nEmOb53zO/TVS+apY2p74pDxRlTr/cZoNH2fgvHo+Knt6ssTALDDrJy7NrySWB7tl1Ip2XVG55eP94FpJrOPzv8db+aOl+NN5/yOhg8C4mq93xgNgoKYIye+02Q1bXKb9ubJoDVtcn1PiLRk8dycTljS+Gl6qxdpXOO/qXNe3ew40kbHSzSiRugbxOWDiNYW01c+9s5O94aLzlBba+4127ZW0w0XnVHrqpVlvDa91ROu8aerEXauQFwj7DeavqUgm+Y437C97P1GHNo3Hpve6smV556gOyKdUqPlzSDtIa+tZnkDgHrauZYr7W2K6muE/UbTBwXFcHBFPs18jb8ecgQ0ws61HPWwTVF9jbDfMG/y5rZJM0/zmVd/U1Lmuvt4aWbnrAPVsmjFo3k7+XVMbdcTS8+vWT2Wd/XW9c61HPWyTdEczOwpd1+Q7zFaCiKyY/kb+eDZ1dOnG9dtyRk22bevX0vu2Syp8mcdBB/Np16GvI6njpf1sk1RffW+z6SjYUwj/wi7evq05J7NefMoDAy6vvyjLRV/PTInNp+pCaNvGPI6euRdaA6NsM8kKIhp5B/hl3+0ZcQkIlH5hleOBZkTm09XT59+/fbhEeVtrUxrOxbjOYMf3jGafWatJ/7i8kFEo/8IK33QL4Ymz+az8qGtOXPcD3OvqybQRhMd6dS3r1+tZjkHi/i2rfcmaORX7j4zjQ6oTR8UFBqSWEj8R3ne6TP02HOv1/WPdGp7ZZMukTmxeup1p5+08xoYynT8Gy/X+NOQ/XyLHQQYqdC4prS35b28OyVh31yoZaFan3XNLh+Y2T+Y2W4z+1mkbLqZPWxm28LfaZHHlpnZdjPbamaLI+Vnm1lveOxbZpmByWY2ycxWh/INZja7lHqdftxRenHFhXpi6fl5N3K+ppt814XuWL8j5/8ld2+uq+tEbS2mG/+gskmXaPKsjq6ePl23elPO9+m61Zvq4vuUtPOSklO4ojRdPX36wprNRZuXuWzXuOKfW7HyfCddhcoroZZ9Cm6TdEGsbKmkR9z9NEmPhP9lZu+VdIWkM8Iy3zaz7NHnO5KulXRauGXXeY2kve5+qqRvSPraWCuc1Cnkyz/akvghZg0MuW5cV9mOfWOx8rL3VzyyJHNidVy/elNZ5bU0MDiU+Fg9ZhNMuh5b6+u0pdRz2drexG2YbaFZ3tWbyoEClXHwcP7fT1J5GhkQa3b5wN3/Jc/Z+8WSPhzu3y7pcUlfDOU/cPeDkl40s+2SzjGzlyS9292flCQz+56kTkkPhmVuDOu6R9L/NjPzMSRiSIrIiwUEWfU0m2K06bGSzdKVSO5Ur03laUk67CYfjmu3Dd88lPzdr7dcgl09fVpy9+bhPhDZFrzul/fo3qf66qr5vdiJxvFT24dn2EvSwMkckSCNdN5p9yk41t1fkyR3f83MjgnlHZLWR573aigbCPfj5dllXgnrOmxm+yUdLemX8Rc1s2uVaW3QiSeemFi5eu4wl+8gUMoy9XYtsqunT1+4e7MGIzvuL9xdnZwK40FXT1/eTmf18LlOnFBfg5luXLdlRKfIgSHXqg07FN+nppmjpKunr2gn4dlHtxe9PFOHDTWIMUlJH9OcZQ+MSMTVkdBvq6OK/bbSDgqS5It5vUB5oWVGFrrfIukWSXrXrLl+8tL7855dJXWkm9repoOHh0puMai0pIPAkRNbE8/kPnrz43rr0Mg6p52w6Uv39Q4HBFmDQ64v3dfbMEFBPGHUtMltuuGiM6pS/+tWb9J1kcsIHVPb9dahwzX7XNtaMp0K80lqAk1LUktd0sGzmicBhbIvlpI/ZP0Le1O9PNOo2SOzJ0/ZER2D7uoYY0vaWFrlrlp4YmJrT/bzHXQffk4aM96mHRTsMrOZoZVgpqTdofxVSdEk5rMk7Qzls/KUR5d51cwmSJoiaU+xCgwMDuV0DpTeObtK+kCyHfayXwxZ/h1NtaZYTrqsMbW9TW2tQ3lzFWzb/Wbi+tK8FpkUxBRqpq4n8SZqKTM09LrVm9T98p5R7TgntJgO5xv2l0ehz64aB7mkgKDaanF55Ii26rR0xJv9ozv9mzrnlTSUOHswTiMwKFb/aqjE5x0/ecpuu7G0pI21VS7f3AdJn+mq9TuGn1/Ly6tpBwXrJF0taUX4+8NI+Z1mdrOk45XpULjR3QfN7ICZLZS0QdKnJP11bF1PSrpU0qPl9ifIdg7MbvDO+R36m8e25RxQZ007IudxaeSPJuvCM2eW8/IlS9rZ7+8f0DcuPyvnTBLVlThuX9Id63dowUnTy/4B/6/L3l+RzzDf0NByd7bx5xdS6SGv0TqMZkc8bXJbWbk7qtXSkdTsf9eGV0o+qLaa6ZQZkwsG9+WehJT6XahE/ct5/aTPu/vlPWUN+8538pQVHa1Rzu+hEkME4+m5Zy+9P+/z0moXqllQYGZ3KdOp8D1m9qqkG5QJBtaY2TWSdki6TJLcfYuZrZH0rKTDkj7r7tlP4jPKjGRoV6aD4YOh/LuSvh86Je5RZvRC2aJNjlfd+uSIH+G23W/qqluf1KpPf0hS5oud9KN57LnXy3rtUn+khfIDdM7vaKigIOkaWy36TBVrEi3l8yjWyvLFe58pOyio1Gc4eWKLFq14NCeXxp3rdwx3WOzb1z88oiFpOG68o14h+/oHtGjFoxU/kxntjviGi87Qkns257SctbVaYtbPEhrH8IQAABgzSURBVBtnCsr3nalEZ7FTZkzW9gIBQVur6YaLSh9ynNQJUxr5XahGZ7dCgV7S571q/Y7hfUUpgWGxlrLs97/U30P2OeWUR42m9WNcJy9y9ysTHvpIwvO/Iukrecq7Jb0vT/nbCkFFpTzxfP6rD9nyYsOIymmWL+fDX7J4bt6DRiPmB/itOdPzbuffmjO9qq+b1CS6av0OXbXwRC04aXrOASVpUqliTbr5zj5L2Tm02NgPUtGANptLI25I0rK1+QOXfB31iqnGTqtYFrirbn0y5zu0aM50rfr0h3KyBEa3dbWC5q6ePl2/ZtPw59a3r1/Xr9mU+FmWM6zshdffKnjmuPLS8oYcJ3XCjLaUZiXVv2UMkXuhQC9pvxmvQrHAMOnkKSr+6yz0e5CSf+/FPstC+/dCxnXyokZRThPcl+7rLdrZsNTxz+UkJLm7O39HlaTyaiplvHeh57z0q/w/2qTysdYla1VCZx9Xptn/i/c+M+KMMt+kUuWeLZU6Icp/ODd5VEyl9Sd0FBjtkNpKJ9IpNFlQPCCQMkH7Vbc+KSkTmDyx9PyCCcoq5Yv3PjPi4DnkycHdwlMyudpKiQ0q3Zcg6bPNVz4pYVSJe+n7t7hKpUgv9PzZRydf7oonXYtK+j1Io281GW3CqfGevKjutZhKboJb3tVbUme4UneO5fxIirVg1EopB7jszI052R7veSfbY6V2Dtnm0FKzShbbxSZdX9771kBO8FFuEpFSdw4LTpped+P+y1GpTo5dPX3a8+bBvI+dd/qMUf0WkoZzTW1vG1NCo3L7JDy9Y7+6evp0VQkBYLHvWTVn2ns74SDpY3jdSs0KWahz6PoX9iY+9tVLRtcXIulTKPZbHe1+Lo3kRQQFEa2x9rBFCU3Yi+ZMLzmla6k7xzSnTp0wyu9XKQe4fDM3Dgy6rl+TSdtbqfddqDm00qLBR7EzhGOPmpjzf7Gdw/KuXs1Z9oCuW70ptY5GWWMZPVOJ7+07Ta75D0rl9tnJmjwx/25vf//AiNTSH7358ZLquWjFo2XXI/tbWXDS9BH7nrgrzz1Bn1yYHDxUM81xoc9ytK+blCL9vNNnlLWe/oGhxKCk0G+zlBajeMvj8q7exN+kSzlp8OPB5Wj3c2kkLyIoiBgY9Jwv+KpPf2hEYJC9XlnqhxL90As1b1dyHoFyj/H/6xNnlf0aUmnRb1Lv7yGXltyzWeedPmPEl7BF5fePKKc5VBpbR8ZyrrO//utDOf8X2jlk+zlU6wdf6Me+vGvk9c0bLjpDba3lb6m2lspMo1yo97hUWsCd7zeX1IM/31bPdiwutP7rwzwVo7FzX79WPrR1RK6OuAUnTddNnfMKBgbl1CEpBslXnm/fFDWaVqGkFOk/3vxa2esaTVDS1dNX8Kx/9tL7R8w/UiibpPROIBlfbtna3sRAtNAlDim5VasZkxelJv4Fz44yiCuUmSorelDP19Hk85Gx7EmdokZzDbTcQ8poOq109fSpJaHTTYuZunr61P1y4csZA4Ou1Rt35O3s0/3ynqpe/63VWXh8X18oGcnnS+wA99KKC3P+P3np/YnvJ9sxKju64q4NO5Sv832+4ZOd8zvU/fKe4REaJatQy2axg1xbq+lQwkgCafSdu+IKXYpYtvaZgumniymlM1z2dTrnd+imznlavXFHYr6IfBkv80mKQfKVZ9f3+YTWq0KTZBXyN49tG37vffv69TePbRtVP5bRBGTL1hY+66+k/oHBxEC02CXfcpMXVSLJFC0FMaUmMCnW3CcpZ3KgfGc92U5tXT19Wt7Vqy+syTRLt5jpvNNn5Py4o2c8SbIdgsqNIsv9URUbdTHorutWbyoaWUvJyXAqOeNePUx4k9U5v0MfP7tj+Jpgq5k+fnZm/ohSd0azl96vU5bdr9nh7DdppEZryztB26C77n2qL29AkHXd6k2avfT+4TPjrp6+sEx5u8l4i1u1FAoIpMz7yXd5q5IKdUorppwWlejrFHrJUi+XlXsG2jm/Q5Mn5m8tKDRJVpKP3vx43uHeo5F0fT3pvbSapZaNNp9CrTblTDoXb2nMjqjK1wpYCC0FMaV0Flre1VtSxrm7u3cMf3iFmtjiQ6SyH+aGF36lh6//8IgznmJ1X7J47ogse5VUrFm3EirZhF4PczxkxQ+02YP1gpPKG4IZHfa2+8DbWjRn+nAq3FYzHdHWMqIjbKmfWbb3/ku/6h/15xz/vjdqmty4cpI5FTWKFpViwW2pZ9rnnT4jZ9y/VPgMtKunr2LZRwtdwhmN7G8pPhLltGOOVHtb64iz7HoKCKTirTalTjqXdBJ2RyQzYikICmJKOY6Wehb7xPN7tLyrVzd1ztOEAjnjk2zb/aaWd/XqsedeL/uLfOSkCVWbpbEWE0VVundtfGzvooT8CMWUctkoKt5ZL6lz5vWrNxWcu6KQgUHXs68d0PNf/b3hsqQsaaV64vk9Y7oKED1gFkqTu+Ck6Q0zQ2a5yZykzPflG5eflXf8fbktKtmTg7Hq6unTnRt2jPgeZ1usRvO62e9bdN6PeAA1++h2/b/n91S8eb4jYWjqtt1v6rRjjtRbh4Zyvl+fX7OpppNHFcs5ksakR4UQFMSUcjAq5yw2G6WNtpUxHs0XE591sJzlsjuEpGQwWaVeBx2LK889ofiT9M6ZWymidV716Q/lbcIsptx9SXyIa1JANSTpXZNa9fbhobI/O2lkh85yg5d8xvI5R3uRJwXRq9bv0OqfvpKYIGq0QVI1ZC/blbtNjzlqojrndyT2F9m5r7/kz6pSLXT/be3IfAqSdGfCGWU5rxud9yM+PXWp36WJRfqKxM0+uj0xwN+2+80RfXBqnfG12M959tH5f2fZToi1nlqePgUx73lXdfK3j1Y5O6FFc6bnnXWwFNkDa7FkMFLxHrPlaDXTJxeemHON/ZMLTyypuSuaJ6FcXT19enXv22UvV674j7dQk/OuA4c0NOQ6cmKrTJlx86MdFliJE6Fyh4dF3RlrGcjHpYIJos46YcqoX7/SXKPbprsOHNJHb3684KiTUtdbqRa6txLOUIaUfxTKaF531fodow5gypyypuQWv9EOHa22pPr/vxf2lJzsrJJoKYjZdeBQ8SeVaaxNuaXIns2P9rWyB9ZSksFUMknSoPuICUJKNZYzp2LLtmhkCtTRiPcGL5Zm15W5RrtoznQ9vWN/We8vOs/BWB171MRRDQ/Lim67cmf3y7Z61DoZV7Vs2/2mvnn5WSP6+WQ7GpZ65jqWlpton45C7li/Y/jSzmnHHKmHr//wqF53LEFpNWbiLLVfVj1xJ81xw0jrWk8+L624UC+tuDBx6GS9a29r0ZxlD2j20vs1Z9kDZfWULXdHFb00VOjsZ9rktopNoxu/tFHqD/mJ5/eUvQOLnk2M1S9/PTDmPinZ1qVSLwWNd/EDcrmdaUeb++GqW58cVf6Lbbvf1Edvfjwxh0qjmLPsgZJS0tejSmV8LQdBwSgsWTy34iloR7u+bKatYsMVS5HGsL3+gaExD6EpVfTgVOhsev9bA4lNrOWKH6DrZWhkMZUY/ZE908+Xsa+UIb2FNFoK6BvXbck7L8KN67aU1I+prWV0I2e6evrG1OKybfebicPiJlcocK62Qfcx903pmNo+IjtpLbQkfDeqmem2MT7VGiu24+6c36GrCmQWG43R7oKzmbayZ4ljcX2dTLlcyRwFUv5+CoWytFWy9TL+k67F+P1KGeNxe1i+jH3F+r0U+w2mnQK6XIUybpYSgA0MjS6g/NJ9lQmwu1/eo1/sf1su6Rf731b3y3s0qYFaC8Zi2uQ2PbH0fG340kdr/tr5vhtJQ0eTgrRygzf6FOTxhTX55xWPuqlzXknJeRpJsYPh7KX3J84HUUmVzFHQMbVdTyw9f0R59rOtdk/k+DupxXDOSqlUmovRvOdGCp7GqtQ+F//1ns1FRyrEO6ZWYvRGvJ9SdEhpM9gXGdkzbXJbYur2asrG54VGH/zlJWfmTN0tZQL7v7zkzOH/syMZJh536tlJr0VLQR6D7iX18KynvgW1Uk+dv4oFKMXmjkhjPPxoU8LWWiXyRGQ/n9E0dTZS8DRWpQbBhwa9YEDQ1molz/KK0kW/v++deVQqdciOfsnOrzB76f0jJuvqnN+hmz9xVs5lnps/cdbwfq7U0VoEBQlKmf2rEpO+YPTyTVgVNWvaESMO/PEJcqot3nRXxRlPK6oSrTXrX9ir5V29RSfUyef4qe0axVxMDalSibpWXvr+nO97tfrmRDVSh8PRMOXu5wtNx1xr2Y6gUZ3zO/TE0vP14ooL9cTS83O+D6WO1uLyQQF9+/o1Z9kDialZi034g9H76M2P6+HrPzz8fzSBx5T2NpllmvWOn9qub15+lu7u3pE3o9lVtz45PDIj3wQ51Ra/7ppG0+NoVCL5UbSZ+auXzBv+/FRk3W2t5Q3Va3SVulwWDwhq0cT/8bM7Ck7QVG/K+V6bpKsWnqjul/foC2s2V3W64tEqJ/laqfs7WgqKiPeMzw6zqtWPrllt2/2mzv3Kw5JCetl7Ng93ptzXP6C9bw3kNKeVkl+hFnM2xO1rkCAgrpK7v7s2vJJzBlNo3UdObB1xxjveVeMyZKU76ya596m+hgkIpPK+11Mnt+nF139d1enMKy3fVOHlIigo0xPPZ7JMERBU364Dh9TV06cv/2jLiMx3o1GLloG4ag4dahTl7FCrNIdXTZW7U63GZchaHcQacex/qfa+NVBXfaiKqVT2Qy4f5JE0QUVWvQzdawaN3oQ8llTB40k022KhOQ2qna2tFuYcc2RFZwEsxWjTYY9nlbgEVu9OO+bI4ftJ2Q+vW72prP0oLQV55BvCFtVArWVI2VhSBY8n0bOXYmeXabToVFK5AcFYA19GHeQ33gMCSTn9rio1YoegIIaIe3zK9k+otX39A2O6vjcelXKJYHlXb01yYowH0ye35bSs8D1rHtERJpW6VElQEHPhmTMllZ8FqpFVKnNdPavGRFelyp4hL7l7c05zH5KtWr+jYefzqLVdBw7pzBt+IikTEIyHy5vvnjS+hzpWyh3rd+jMG36iOcseqFgLW/Mc+Up071OvSsrNAjXejYfOXYXUYrx2KQaGvObXmhuVq34+t0bwxsFBnfuVh7Vs7TPj4vLmGwfHbwfGSnvj4GBFO5YSFMT0h/E1jdzRCbkYKdKY+NzKs+vAoeH9FzBajD7II57rGwCAZkBLAQAAkERQAAAAAoICAAAgiaAAAAAEBAUAAEASQQEAAAgICgAAgCSCAgAAEBAUAAAASQQFAAAgICgAAACSCAoAAEBAUACgYRx71ES9tOJCfXLhiWlXBRiXzCs4D3MjapnY3t929Kwj0q5HVbi7zCxaNNh/4PXW9qNmVPZ1Mi8Wf61SDL61X62Tp1S0OjlcGnz7wOuD+3cNz8M78bhTz67U6ocO9b9xeE/ftkqu14eGDltLy4To/wO7X9gcfc7EY+fMl1l5Qb0PDfnQ0GFrnTAxW1T17V9BPnj40MDrL/VGyyr5Waal1p/BYH/m91C1bec+dGjX8z0Tjz31bJWzR3CprOdXSHT7++DhQ9HfR9lcOvzG7heH+t/YI0kTjz1lvqzlnd+pDw0Nvv3mryq+D47V4dCu7U9FiyYeO+cD0f3z4f27NfjW/rxbu+mDAqTLzLrdfUHa9WhWbP/08Rmki+2fi8sHAABAEkEBAAAICAqQtlvSrkCTY/unj88gXWz/CPoUAAAASbQUAACAgKAAFWdmL5lZr5ltMrPuUDbdzB42s23h77TI85eZ2XYz22pmiyPlZ4f1bDezb9kohjw2CzP7BzPbbWY/i5RVbJub2SQzWx3KN5jZ7Fq+v3qXsP1vNLO+8DvYZGa/F3mM7V9BZnaCmT1mZj83sy1m9rlQzm+gXO7OjVtFb5JekvSeWNlfSVoa7i+V9LVw/72SNkuaJOlkSc9Lag2PbZT0IWVGLz8o6d+n/d7q9Sbp30n6gKSfVWObS/pjSX8b7l8haXXa77mebgnb/0ZJf57nuWz/ym//mZI+EO4fJelfw3bmN1DmjZYC1MrFkm4P92+X1Bkp/4G7H3T3FyVtl3SOmc2U9G53f9Izv8LvRZZBjLv/i6Q9seJKbvPouu6R9BFabt6RsP2TsP0rzN1fc/enw/0Dkn4uqUP8BspGUIBqcEn/ZGZPmdm1oexYd39NyvyAJR0TyjskvRJZ9tVQ1hHux8tRukpu8+Fl3P2wpP2Sjq5azcePPzGzZ8LlhWzTNdu/ikKz/nxJG8RvoGwEBaiGRe7+AUn/XtJnzezfFXhuvkg7KeEpQ2UqYzTbnM+jfN+RNEfSWZJek/T1UM72rxIze5ekeyVd5+5vFHpqnjI+AxEUoArcfWf4u1vSfZLOkbQrNM0p/N0dnv6qpBMii8+StDOUz8pTjtJVcpsPL2NmEyRNUenN5U3J3Xe5+6C7D0m6VZnfgcT2rwoza1MmIFjl7mtDMb+BMhEUoKLM7EgzOyp7X9LvSvqZpHWSrg5Pu1rSD8P9dZKuCD17T5Z0mqSNoanvgJktDNftPhVZBqWp5DaPrutSSY+Ga65IkD0YBR9T5ncgsf0rLmyv70r6ubvfHHmI30C50u7pyG183SSdokyv3s2Stkj6Uig/WtIjkraFv9Mjy3xJmd6/WxUZYSBpgTI70ucl/W+FZFvc8m73u5Rpoh5Q5ozmmkpuc0lHSLpbmQ5ZGyWdkvZ7rqdbwvb/vqReSc8oc0CZyfav2vb/N8o05T8jaVO4/R6/gfJvZDQEAACSuHwAAAACggIAACCJoAAAAAQEBQAAQBJBAQAACAgKgAZjZm5mX4/8/+dmdmOF1n2bmV1aiXUVeZ3Lwox2j8XKjzeze8L9s6IzC1bgNaea2R/ney0AGQQFQOM5KOkSM3tP2hWJMrPWMp5+jaQ/dvfzooXuvtPds0HJWcqMNS+nDhMKPDxVmZnu8r0WABEUAI3osKRbJH0+/kD8TN/Mfh3+ftjM/o+ZrTGzfzWzFWZ2lZltDHPHz4ms5nfM7P+G5/1+WL7VzFaa2U/DBD//JbLex8zsTmUS9cTrc2VY/8/M7Guh7H8ok2zmb81sZez5s8NzJ0r6C0mXm9kmM7s8ZMv8h1CHHjO7OCzzh2Z2t5n9SJmJuN5lZo+Y2dPhtS8Oq18haU5Y38rsa4V1HGFm/xie32Nm50XWvdbMfmJm28zsryLb47ZQ114zG/FZAI2oUFQNoH79jaRnsgepEr1f0m8qk6/9BUl/7+7nmNnnJP2ppOvC82ZL+m1lJvN5zMxOVSbd6353/6CZTZL0hJn9U3j+OZLe55kpaIeZ2fGSvibpbEl7lTlgd7r7X5jZ+ZL+3N2781XU3Q+F4GGBu/9JWN9fKpNa9j+b2VRJG83sn8MiH5J0prvvCa0FH3P3N0JrynozWydpaajnWWF9syMv+dnwuvPM7PRQ198Ij52lzKx7ByVtNbO/Vma2vQ53f19Y19TCmx5oDLQUAA3IMzPAfU/Sn5Wx2E89M+/8QWVSuGYP6r3KBAJZa9x9yN23KRM8nK7MHBafMrNNykxJe7Qy+eKlTM74nIAg+KCkx939dc9MNbtKUqEZM4v5XUlLQx0eVybt7InhsYfdPTs5jUn6SzN7RtI/KzPl7bFF1v1vlElLLHd/TtLLkrJBwSPuvt/d35b0rKSTlNkup5jZX5vZBZIKzcgHNAxaCoDG9U1JT0v6x0jZYYVgP0zoMjHy2MHI/aHI/0PK3RfEc59np5T9U3d/KPqAmX1Y0psJ9cs31exYmKSPu/vWWB3OjdXhKkkzJJ3t7gNm9pIyAUSxdSeJbrdBSRPcfa+ZvV/SYmVaGT4h6T+X9C6AOkZLAdCgwpnxGmU67WW9pExzvSRdLKltFKu+zMxaQj+DU5SZMOYhSZ+xzPS0MrPfsMwsmIVskPTbZvae0AnxSkn/p4x6HJB0VOT/hyT9aQh2ZGbzE5abIml3CAjOU+bMPt/6ov5FmWBC4bLBicq877zCZYkWd79X0n+X9IGS3hFQ5wgKgMb2dUnRUQi3KnMg3igpfgZdqq3KHLwflPRHodn875VpOn86dM77OxVpafTMNLTLJD2mzKyZT7t7OdNfPybpvdmOhpL+pzJBzjOhDv8zYblVkhaYWbcyB/rnQn1+pUxfiJ/FOzhK+rakVjPrlbRa0h+GyyxJOiQ9Hi5l3BbeJ9DwmCURAABIoqUAAAAEBAUAAEASQQEAAAgICgAAgCSCAgAAEBAUAAAASQQFAAAgICgAAACSpP8PQj3cW6bG5xoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Quite a bumpy ride!</li>\n",
    "    <li>So, let's try <b>simulated annealing</b>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Simulated Annealing</h2>\n",
    "<ul>\n",
    "    <li>As we discussed, SGD does not settle at the minimum.</li>\n",
    "    <li>One solution is to gradually reduce the learning rate:\n",
    "        <ul>\n",
    "            <li>Updates start out 'large' so you make progress.</li>\n",
    "            <li>But, over time, updates get smaller, allowing SGD to settle at or near the global minimum.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The function that determines how to reduce the learning rate is called the <b>learning schedule</b>.\n",
    "        <ul>\n",
    "            <li>Reduce it too quickly and you may not converge on or near to the global minimum.</li>\n",
    "            <li>Reduce it too slowly and you may still bounce around a lot and, if stopped after too few iterations, \n",
    "                may end up\n",
    "                with a suboptimal solution.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)\n",
    "    \n",
    "def stochastic_gradient_descent_for_ols_linear_regression_with_simulated_annealing(X, y, num_epochs):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_epochs * m)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(m):\n",
    "            rand_idx = np.random.randint(m)\n",
    "            xi = X[rand_idx:rand_idx + 1]\n",
    "            yi = y[rand_idx:rand_idx + 1]\n",
    "            alpha = learning_schedule(epoch * m + i)\n",
    "            beta -= alpha * xi.T.dot(xi.dot(beta) - yi)\n",
    "            Jvals[epoch * m + i] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([350.85798617, 175.92858728,  -2.2216496 ,  -1.22026818])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Stochastic Gradient Descent\n",
    "beta, Jvals = stochastic_gradient_descent_for_ols_linear_regression_with_simulated_annealing(X, y, num_epochs = 50)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Mini-Batch Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>Batch Gradient Descent computes gradients from the full training set.</li>\n",
    "    <li>Stochastic Gradient Descent computes gradients from just one example.</li>\n",
    "    <li>Mini-Batch Gradient Descent lies between the two:\n",
    "        <ul>\n",
    "            <li>It computes gradients from a small randomly-selected subset of the training set, called a\n",
    "                <b>mini-batch</b>.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Since it lies between the two:\n",
    "        <ul>\n",
    "            <li>It may bounce less and get closer to the global minimum than SGD&hellip;\n",
    "                <ul>\n",
    "                    <li>&hellip;although both of them can reach the global minimum with a good learning schedule.</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Its time and memory costs lie between the two.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The Normal Equation versus Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>Efficiency/scaling-up to large training sets:\n",
    "        <ul>\n",
    "            <li>Normal Equation: \n",
    "                <ul>\n",
    "                    <li>is linear in $m$, so can handle large training sets efficiently if they fit into\n",
    "                        main memory;\n",
    "                    </li>\n",
    "                    <li>but it has to compute the inverse (or psueudo-inverse) of a $n \\times n$ matrix, which takes\n",
    "                        time between quadratic and cubic in $n$, and so is only feasible for smallish $n$ (up to\n",
    "                        a few thousand).\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Gradient Descent:\n",
    "                <ul>\n",
    "                    <li>SGD scales really well to huge $m$;</li>\n",
    "                    <li>All three Gradient Descent methods can handle huge $n$ (even 100s of 1000s).</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Finding the global minimum for OLS regression:\n",
    "        <ul>\n",
    "            <li>Normal Equation: guaranteed to find the global minimum.</li>\n",
    "            <li>Gradient Descent: all a bit dependent on number of iterations, learning rate, learning schedule.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Feature scaling:\n",
    "        <ul>\n",
    "            <li>Normal Equation: scaling is not needed. \n",
    "            </li>\n",
    "            <li>Gradient Descent: scaling <em>is</em> needed.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Finally, Gradient Descent is a general method, whereas the Normal Equation is only for OLS regression.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Non-Convex Functions</h1>\n",
    "<ul>\n",
    "    <li>The loss function for OLS regression is convex and it has a slope that never changes abruptly.\n",
    "        <ul>\n",
    "            <li>This gives us good 'guarantees' about reaching the minimum\n",
    "                (depending on such things as running for long enough, using a learning rate that isn't too high,\n",
    "                and whether we are using Batch, Mini-Batch or Stochastic Gradient Descent).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>But Gradient Descent is a generic method: you can use it to find the minima of other loss functions.</li>\n",
    "    <li>But not all loss functions are convex, which can cause problems for Gradient Descent:\n",
    "        <figure>\n",
    "            <img src=\"images/local_minima.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>The algorithm might converge to a local minimum, instead of the global minimum.</li>\n",
    "            <li>It may take a long time to cross a plateau.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>What do we do about this?\n",
    "        <ul>\n",
    "            <li>One thing is to prefer Stochastic Gradient Descent (or Mini-Batch Gradient Descent):\n",
    "                because of the way they 'bounce around', they might even escape a\n",
    "                local minimum, and might even get to the global minimum.\n",
    "            </li>\n",
    "            <li>In this context, simulated annealing is also useful: updates start out 'large' allowing these\n",
    "                algorithms to make \n",
    "                progress and even escape local minima; but, over time, updates get smaller, allowing \n",
    "                these algorithms to settle at or near the global minimum.\n",
    "            </li>\n",
    "            <li>But, if using simulated annealing, if you reduce the learning rate too quickly, you may \n",
    "                stil get stuck in a local minimum.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
