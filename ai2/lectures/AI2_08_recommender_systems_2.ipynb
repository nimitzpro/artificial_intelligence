{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4619: Artificial Intelligence II</h1>\n",
    "<h1>Recommender Systems II</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br />\n",
    "    School of Computer Science and Information Technology<br />\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MovieLens Dataset</h1>\n",
    "<ul>\n",
    "    <li>We'll illustrate this lecture using a widely available dataset.</li>\n",
    "    <li>It has \n",
    "        <ul>\n",
    "            <li>943 users, about whom it records some limited demographic data;</li>\n",
    "            <li>1682 movies (items), about which it records some genres and some other data;</li>\n",
    "            <li>100000 ratings on a 1-5 scale.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Dataset contains:\n",
      "b'943 users\\n1682 items\\n100000 ratings\\n'\n"
     ]
    }
   ],
   "source": [
    "# The code in this cell is used in Google's Recommender Systems course: https://developers.google.com/machine-learning/recommendation/\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\", \"movielens.zip\")\n",
    "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
    "zip_ref.extractall()\n",
    "print(\"Done. Dataset contains:\")\n",
    "print(zip_ref.read('ml-100k/u.info'))\n",
    "\n",
    "# Load each data set (users, movies, and ratings).\n",
    "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv(\n",
    "    'ml-100k/u.user', sep='|', names=users_cols, encoding='latin-1')\n",
    "\n",
    "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(\n",
    "    'ml-100k/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
    "\n",
    "# The movies file contains a binary feature for each genre.\n",
    "genre_cols = [\n",
    "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "movies_cols = [\n",
    "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
    "] + genre_cols\n",
    "movies = pd.read_csv(\n",
    "    'ml-100k/u.item', sep='|', names=movies_cols, encoding='latin-1')\n",
    "\n",
    "# Since the ids start at 1, we shift them to start at 0.\n",
    "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
    "ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: str(x-1))\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n",
    "\n",
    "# Compute the number of movies to which a genre is assigned.\n",
    "genre_occurences = movies[genre_cols].sum().to_dict()\n",
    "\n",
    "# Since some movies can belong to more than one genre, we create different\n",
    "# 'genre' columns as follows:\n",
    "# - all_genres: all the active genres of the movie.\n",
    "# - genre: randomly sampled from the active genres.\n",
    "def mark_genres(movies, genres):\n",
    "  def get_random_genre(gs):\n",
    "    active = [genre for genre, g in zip(genres, gs) if g==1]\n",
    "    if len(active) == 0:\n",
    "      return 'Other'\n",
    "    return np.random.choice(active)\n",
    "  def get_all_genres(gs):\n",
    "    active = [genre for genre, g in zip(genres, gs) if g==1]\n",
    "    if len(active) == 0:\n",
    "      return 'Other'\n",
    "    return '-'.join(active)\n",
    "  movies['genre'] = [\n",
    "      get_random_genre(gs) for gs in zip(*[movies[genre] for genre in genres])]\n",
    "  movies['all_genres'] = [\n",
    "      get_all_genres(gs) for gs in zip(*[movies[genre] for genre in genres])]\n",
    "\n",
    "mark_genres(movies, genre_cols)\n",
    "\n",
    "# Create one merged DataFrame containing all the movielens data.\n",
    "movielens = ratings.merge(movies, on='movie_id').merge(users, on='user_id')\n",
    "\n",
    "# Utility to split the data into training and test sets.\n",
    "def split_dataframe(df, holdout_fraction=0.1):\n",
    "  \"\"\"Splits a DataFrame into training and test sets.\n",
    "  Args:\n",
    "    df: a dataframe.\n",
    "    holdout_fraction: fraction of dataframe rows to use in the test set.\n",
    "  Returns:\n",
    "    train: dataframe for training\n",
    "    test: dataframe for testing\n",
    "  \"\"\"\n",
    "  test = df.sample(frac=holdout_fraction, replace=False)\n",
    "  train = df[~df.index.isin(test.index)]\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hackery to insert some extra features\n",
    "\n",
    "# One-hot encode the sex\n",
    "movielens['female'] = (movielens['sex'] == 'F').astype(int)\n",
    "movielens['male'] = (movielens['sex'] == 'M').astype(int)\n",
    "\n",
    "# Genres\n",
    "item_features = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "# User demographic features that we will use\n",
    "user_features = ['age', 'female', 'male']\n",
    "\n",
    "# Insert interaction features\n",
    "interaction_features = [ifeat + '_' + ufeat for ifeat in item_features for ufeat in user_features]\n",
    "for ifeat in item_features:\n",
    "    for ufeat in user_features:\n",
    "        movielens[ifeat + '_' + ufeat] = movielens[ifeat] * movielens[ufeat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test sets\n",
    "train, test = split_dataframe(movielens, holdout_fraction=0.2)\n",
    "\n",
    "movielens_by_user_train = train[['user_id', 'movie_id', 'rating']].pivot_table(\n",
    "    index=['user_id'], columns=['movie_id'], values='rating', fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>User-Item Interactions</h1>\n",
    "<ul>\n",
    "    <li>Recall the ratings matrix, $\\v{R}$:\n",
    "        <table style=\"border: 1px solid; border-collapse: collapse;\">\n",
    "            <tr>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\"></th>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$i_1$</th>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$i_2$</th>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$i_3$</th>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$i_4$</th>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$i_5$</th>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$i_6$</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$u_1$</th>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">2</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">5</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">3</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">1</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">2</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$u_2$</th>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">5</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">5</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">3</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">4</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$u_3$</th>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">3</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$u_4$</th>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">5</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">4</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">2</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">4</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">3</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">3</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th style=\"border: 1px solid black; text-align: left;\">$u_5$</th>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">2</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">5</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">4</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\">4</td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "                <td style=\"border: 1px solid black; text-align: left;\"></td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </li>\n",
    "   <li>We made no use of this in the simple content-based recommender system that we presented in the previous\n",
    "       lecture.\n",
    "    </li>\n",
    "    <li>In this lecture and the next, we will see how we can make use of this data.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Rating scales</h2>\n",
    "<ul>\n",
    "    <li>Before we use $\\v{R}$, let's note a couple of problems.\n",
    "        <ul>\n",
    "            <li>When users give ratings, some users use the whole scale (1-5); others do not (e.g. reluctant to give a 5; or reluctant to give a 1).</li>\n",
    "            <li>Some users are more positive (mostly they give 4's and 5's); others are more negative (their ratings are skewed away from the top).</li>\n",
    "        </ul>\n",
    "        This raises issues about whether different rows of $\\v{R}$ are comparable.\n",
    "    </li>\n",
    "    <li>Solutions:\n",
    "        <ul>\n",
    "            <li>Some recommender systems already takes steps to compensate for these differences in users' ratings scales (e.g. Pearson correlation in the user-based nearest-neighbours recommender below).</li>\n",
    "            <li>Otherwise, we can standardize each user's ratings.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>There are other problems with ratings too. Can you think of any?\n",
    "        <!-- Opinions change over time because tastes change over time. Opinions may need recalibration when\n",
    "             new items come along. Ratings are given some time after consumption: the delay reduces reliability.\n",
    "             Re-rating tasks show that users have some inconsistency.\n",
    "             Item ratings tend towards the mean.\n",
    "        -->\n",
    "    </li>\n",
    "</ul>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Non-Personalised Recommender Systems</h1>\n",
    "<ul>\n",
    "    <li>Using $\\v{R}$, we can define some non-personalised recommender systems.</li>\n",
    "    <li>The obvious one is: $$\\hat{r}_{ui} = \\frac{\\sum_{r \\in \\v{R}_i} r}{|\\v{R}_i|}$$\n",
    "        where $\\v{R}_i = \\{r_{vi} : r_{vi} \\neq \\bot, \\forall v \\in U\\}$ What does this recomender do?</li>\n",
    "    <li>This turns out to be a great baseline to compare against &mdash; quite hard to beat.</i>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.216151909776916"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit: precompute the mean rating and the mean rating for every item in the training data\n",
    "mean_rating = train['rating'].mean()\n",
    "mean_rating_by_item = train.groupby('movie_id').mean()['rating']\n",
    "\n",
    "# Predict: return mean rating for the item or mean of all ratings\n",
    "def predict(df):\n",
    "    return df['movie_id'].apply(\n",
    "        lambda i: mean_rating_by_item.iloc[int(i)] if i in mean_rating_by_item.index else mean_rating)\n",
    "\n",
    "# Testing (error estimation)\n",
    "mean_absolute_error(test['rating'], predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Supervised Content-Based Recommender System</h1>\n",
    "<ul>\n",
    "    <li>If we are going to do supervised learning, then we need a labeled dataset: we need target values.</li>\n",
    "    <li>Let's use the ratings as the targets in a regression task.</li>\n",
    "    <li>What about the features?</li>\n",
    "    <li>Items:\n",
    "        <ul>\n",
    "            <li>We can describe each item $i$ the same way as in the simple content-based recommender: a vector\n",
    "                $\\v{Q}^{(i)}$ whose dimension is $d$, where the features are genres, for example.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Users:\n",
    "        <ul>\n",
    "            <li>In the simple content-based recommender, we described each user $u$ using a vector $\\v{P}^{(u)}$\n",
    "                in the same space, hence having the same dimension $d$ and the same features, e.g. genres.\n",
    "            </li>\n",
    "            <li>But this is no longer necessary because we're not doing item-user similarities anymore.</li>\n",
    "            <li>So $\\v{P}^{(u)}$ can be of dimension $d'$, where $d'$ is not necessarily the same as $d$.</li>\n",
    "            <li>And the features can be genres, but they can be other things instead, or as well. For example,\n",
    "                we can have demographic features such as age and sex.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Interaction features:\n",
    "        <ul>\n",
    "            <li>And we can have interaction features (remember these from feature engineering?).</li>\n",
    "            <li>This gives us $d \\times d'$ additional features.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>(Note that the ratings are not used as features. Contrast this with collaborative recommender \n",
    "        systems below.)\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Linear regression</h2>\n",
    "<ul>\n",
    "    <li>Using the features from above, we can learn any model we like.</li>\n",
    "    <li>Most obvious is a linear model, hence we have linear regression.</li>\n",
    "    <li>If we assume that there are $d=3$ item features and $d' = 2$ user features, then the predicted ratingis\n",
    "        $$\\hat{r}_{ui} = \\v{\\beta}_0 +\n",
    "                        \\v{\\beta}_1\\v{P}^{(u)}_1 +\n",
    "                        \\v{\\beta}_2\\v{P}^{(u)}_2 +\n",
    "                        \\v{\\beta}_3\\v{Q}^{(i)}_1 +\n",
    "                        \\v{\\beta}_4\\v{Q}^{(i)}_2 +\n",
    "                        \\v{\\beta}_5\\v{Q}^{(i)}_3 +\n",
    "                        \\v{\\beta}_6\\v{P}^{(u)}_1\\v{Q}^{(i)}_1 +\n",
    "                        \\v{\\beta}_7\\v{P}^{(u)}_1\\v{Q}^{(i)}_2 +\n",
    "                        \\v{\\beta}_8\\v{P}^{(u)}_1\\v{Q}^{(i)}_3 +\n",
    "                        \\v{\\beta}_9\\v{P}^{(u)}_2\\v{Q}^{(i)}_1 +\n",
    "                        \\v{\\beta}_{10}\\v{P}^{(u)}_2\\v{Q}^{(i)}_2 +\n",
    "                        \\v{\\beta}_{11}\\v{P}^{(u)}_2\\v{Q}^{(i)}_3$$\n",
    "    </li>\n",
    "    <li>Now we can use OLS regression!</li>\n",
    "    <li>The number of parameters here is $1 + d' + d + d'd$ and this might cause various problems but we already know some solutions (e.g.\n",
    "        dimensionality reduction, regularization, &hellip;).\n",
    "    </li>\n",
    "    <li>Once we have learned the linear model then, for a user $u$, we can predict a rating for each candidate and\n",
    "        use these as the scores to order the candidates.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.915039417757867"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features for the linear regression\n",
    "features = item_features + user_features + interaction_features\n",
    "\n",
    "# Training\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[features], train['rating'])\n",
    "\n",
    "# Testing (error estimation)i\n",
    "mean_absolute_error(test['rating'], lr.predict(test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>This is only a little bit better than the non-personalised recommender.</li>\n",
    "    <li>We could probably improve it with more features of perhaps regularization, etc.\n",
    "        We should also probably be rounding up/down any out-of-range predictions so that they fall within $[1,5]$,\n",
    "        and possibly even rounding each individual prediction to the nearest integer.\n",
    "    </li>\n",
    "    <li>We should have done some model selection with a validation set but, to keep the code simple, we\n",
    "        ignored this.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Collaborative Filtering</h1>\n",
    "<ul>\n",
    "    <li>Above, we used a user's ratings as her target values.</li>\n",
    "    <li>Here, we will use ratings as both target values and features.</li>\n",
    "    <li>We'll look at two more recommender systems. \n",
    "        <ul>\n",
    "            <li>User-based nearest-neighbours;</li>\n",
    "            <li>Matrix factorization.</li>\n",
    "        </ul>\n",
    "        The first is instance-based; the second (next lecture) is model-based.\n",
    "    </li>\n",
    "    <li>Both are examples of <b>collaborative filtering</b>:\n",
    "        <ul>\n",
    "            <li>To predict $\\hat{r}_{ui}$, use other people's opinions of $i$.\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>User-Based Nearest-Neighbours</h1>\n",
    "<ul>\n",
    "    <li>The idea is simple. To predict $\\hat{r}_{ui}$,\n",
    "        <ul>\n",
    "            <li>find $k$ people who are similar to $u$ (the nearest-neighbours);</li>\n",
    "            <li>take the mean of the neighbours' ratings for $i$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>User-based nearest-neighbours: some details</h2>\n",
    "<ul>\n",
    "    <li>How do we compute similarity of two users, $u$ and $v$?\n",
    "        <ul>\n",
    "            <li>We take their vectors of ratings.\n",
    "                <ul>\n",
    "                    <li>e.g. $u_2$ is represented by $\\rv{5,5,\\bot,3,4,\\bot}$</li>\n",
    "                    <li>e.g. $u_3$ is represented by $\\rv{2,5,4,4,\\bot,\\bot}$</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>We compute cosine similarity, for example.\n",
    "                <ul>\n",
    "                    <li>In fact, Pearson correlation (details not important), which lies in \n",
    "                        $[-1,+1]$ is more common. It has the advantage that it takes into account some of the\n",
    "                        variation in users use of the rating scale that we mentioned above.\n",
    "                    </li>\n",
    "                    <li>In fact, modifications of Pearson correlation (details not important) are used to adjust \n",
    "                        for the case where $u$ and $v$ have\n",
    "                        few co-rated items and to deal with some edge cases.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>How many neighbours, $k$?\n",
    "        <ul>\n",
    "            <li>This is a hyperparameter, whose values can be chosen through a grid-search. Values of 50 or \n",
    "                100 are common.\n",
    "            </li>\n",
    "            <li>However, there are variants (details not important). For example, instead of finding the $k$ \n",
    "                most similar neighbours, we might find all neighbours whose similarity to $u$ exceeds some \n",
    "                threshold $\\theta$. Or we might include a constraint too: e.g. we only include neighbours \n",
    "                who have a rating for candidate $i$.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>How do we make the prediction?\n",
    "        <ul>\n",
    "            <li>Simplest is just the mean of the neghbours' ratings for $i$.</li>\n",
    "            <li>But we may want a weighted mean, where weights are similarities. And, if using Pearson, we may\n",
    "                want to exclude neighbours whose similarity to $u$ is negative. And we may need to handle \n",
    "                edge cases, such as where none of the neighbours has rated $i$.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>     \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't rely on this implementation!\n",
    "# On the one hand, it is over-complicated because of the wrangling it has to do to the dataframes.\n",
    "# On the other hand, it makes many simplifications, e.g.: \n",
    "#    it uses dot product (unnormalised cosine) as the similarity measure instead, e.g. of a variant of Pearson\n",
    "#    it predicts the mean of the neighbours ratings, rather than a similarity-weighted mean \n",
    "#    if no neighbour has a rating for the item, it predicts the mean of all ratings rather than, e.g. the mean \n",
    "#                                                                                       of that user's ratings\n",
    "# and so on.\n",
    "\n",
    "def sim(u_ratings, v_ratings):\n",
    "    return u_ratings.dot(v_ratings)\n",
    "\n",
    "def user_based_nn_collaborative_filter(u, i, ratings_by_user, k=50):\n",
    "    # No ratings for i at all\n",
    "    if i not in ratings_by_user.columns:\n",
    "        return mean_rating\n",
    "    # u's ratings\n",
    "    u_ratings = ratings_by_user.loc[u]\n",
    "    # Find which k users in R are the most similar to u (excluding u herself)\n",
    "    nbrs = sorted([(v, sim(u_ratings, ratings_by_user.loc[v])) \n",
    "                   for v in ratings_by_user.index if u != v], key=lambda x: x[1])[::-1][:k]\n",
    "    # Return the corresponding mean target value from R\n",
    "    nbrs_ratings = ratings_by_user.loc[[v for v, sim in nbrs]][i]\n",
    "    num_nbrs_ratings = np.count_nonzero(nbrs_ratings)\n",
    "    return nbrs_ratings.sum() / num_nbrs_ratings if num_nbrs_ratings > 0 else mean_rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194158637959997"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning - takes some time to run!\n",
    "\n",
    "predictions = [user_based_nn_collaborative_filter(u, i, movielens_by_user_train) for (u, i) in test[['user_id', 'movie_id']].values]\n",
    "mean_absolute_error(test['rating'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Discussion of user-based nearest-neighbours</h2>\n",
    "<ul>\n",
    "    <li>Advantages of user-based nearest-neighbours collaborative filtering include:\n",
    "        <ul>\n",
    "            <li>It does not require any item or user descriptions, just user-item interactions (e.g. ratings) &mdash;\n",
    "                and this is data we will collect during the normal operation of the system.\n",
    "            </li>\n",
    "            <li>It may recommend items that are pleasantly surprising (certainly more so than content-based\n",
    "                approaches), since it recommends using <em>other peoples'</em> tastes.\n",
    "            </li>\n",
    "            <li>New ratings can take immediate effect.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Its disadvantages include:\n",
    "        <ul>\n",
    "            <li>It is slow at prediction time. (It can be sped up by caching some of the computations\n",
    "                during 'fitting'. But this may work in opposition to the point above about new ratings taking\n",
    "                immediate effect.)\n",
    "            </li>\n",
    "            <li>It has problems recommending to cold-start users and recommending cold-start items.</li>\n",
    "            <li>It can exhibit popularity bias: over-recommending popular items (although this may depend to\n",
    "                some extent on details of the implementation).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Can it explain its recommendations?\n",
    "        <ul>\n",
    "            <li>Some people say, No. Displaying the identities of the active userâ€™s neighbours is unlikely to be \n",
    "                effective, since the user will in general not know the neighbours; displaying their ratings is \n",
    "                unlikely to be effective, since even the ratings they have in common with the user will be too \n",
    "                large to be readily comprehended.\n",
    "            </li>\n",
    "            <li>Some people say, Yes. You can summarize the neighbours' opinons, e.g. using a histogram that shows\n",
    "                how many of the $k$ neighbours awarded the item a 5, how many a 4, and so on. \n",
    "                (I have also published work that gives another way of explaining user-based recommendations.)\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>In concluding, let's mention that it is also possible to build <em>item-based</em> nearest-neighbours collaborative\n",
    "        filters.\n",
    "        <ul>\n",
    "            <li>Without going into details, these use the similarities between item ratings (columns in the\n",
    "                matrix, rather than rows).\n",
    "            </li>\n",
    "            <li>Famously, this is one of the methods used by Amazon.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
